{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>title_bout</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_avg_BODY_att</th>\n",
       "      <th>B_avg_BODY_landed</th>\n",
       "      <th>B_avg_CLINCH_att</th>\n",
       "      <th>B_avg_CLINCH_landed</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_class_Women's Strawweight</th>\n",
       "      <th>B_Stance_Open Stance</th>\n",
       "      <th>B_Stance_Orthodox</th>\n",
       "      <th>B_Stance_Sideways</th>\n",
       "      <th>B_Stance_Southpaw</th>\n",
       "      <th>B_Stance_Switch</th>\n",
       "      <th>R_Stance_Open Stance</th>\n",
       "      <th>R_Stance_Orthodox</th>\n",
       "      <th>R_Stance_Southpaw</th>\n",
       "      <th>R_Stance_Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.354839</td>\n",
       "      <td>11.322581</td>\n",
       "      <td>6.741935</td>\n",
       "      <td>4.387097</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Winner  title_bout  no_of_rounds  B_current_lose_streak  \\\n",
       "0    Red        True             5                    0.0   \n",
       "1    Red        True             5                    0.0   \n",
       "2    Red       False             3                    0.0   \n",
       "3   Blue       False             3                    0.0   \n",
       "4   Blue       False             3                    0.0   \n",
       "\n",
       "   B_current_win_streak  B_draw  B_avg_BODY_att  B_avg_BODY_landed  \\\n",
       "0                   4.0     0.0        9.200000           6.000000   \n",
       "1                   3.0     0.0       14.600000           9.100000   \n",
       "2                   3.0     0.0       15.354839          11.322581   \n",
       "3                   4.0     0.0       17.000000          14.000000   \n",
       "4                   1.0     0.0       17.000000          14.500000   \n",
       "\n",
       "   B_avg_CLINCH_att  B_avg_CLINCH_landed  ...  \\\n",
       "0          0.200000             0.000000  ...   \n",
       "1         11.800000             7.300000  ...   \n",
       "2          6.741935             4.387097  ...   \n",
       "3         13.750000            11.000000  ...   \n",
       "4          2.500000             2.000000  ...   \n",
       "\n",
       "   weight_class_Women's Strawweight  B_Stance_Open Stance  B_Stance_Orthodox  \\\n",
       "0                                 0                     0                  1   \n",
       "1                                 0                     0                  1   \n",
       "2                                 0                     0                  1   \n",
       "3                                 0                     0                  0   \n",
       "4                                 0                     0                  0   \n",
       "\n",
       "   B_Stance_Sideways  B_Stance_Southpaw  B_Stance_Switch  \\\n",
       "0                  0                  0                0   \n",
       "1                  0                  0                0   \n",
       "2                  0                  0                0   \n",
       "3                  0                  0                1   \n",
       "4                  0                  1                0   \n",
       "\n",
       "   R_Stance_Open Stance  R_Stance_Orthodox  R_Stance_Southpaw  R_Stance_Switch  \n",
       "0                     0                  1                  0                0  \n",
       "1                     0                  0                  1                0  \n",
       "2                     0                  1                  0                0  \n",
       "3                     0                  1                  0                0  \n",
       "4                     0                  0                  1                0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ufcdata/preprocessed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partitioning the dataset to X as predictors, and y as target\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3592 entries, 0 to 3591\n",
      "Columns: 160 entries, Winner to R_Stance_Switch\n",
      "dtypes: bool(1), float64(134), int64(24), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that there are two non-numeric features, winner and title_bout. The winner will be used as taget but the title bout will remain as a predictor and will be encoded with dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the title_bout feature\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X_1.fit_transform(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Dimension:  (3592, 159)\n",
      "\n",
      "y Dimension:  (3592,)\n",
      "\n",
      "First row title bout value: 1 is True, 0 is False ==>  1\n",
      "First row corner value: 1 is Red, 0 is Blue ==>  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>title_bout</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_avg_BODY_att</th>\n",
       "      <th>B_avg_BODY_landed</th>\n",
       "      <th>B_avg_CLINCH_att</th>\n",
       "      <th>B_avg_CLINCH_landed</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_class_Women's Strawweight</th>\n",
       "      <th>B_Stance_Open Stance</th>\n",
       "      <th>B_Stance_Orthodox</th>\n",
       "      <th>B_Stance_Sideways</th>\n",
       "      <th>B_Stance_Southpaw</th>\n",
       "      <th>B_Stance_Switch</th>\n",
       "      <th>R_Stance_Open Stance</th>\n",
       "      <th>R_Stance_Orthodox</th>\n",
       "      <th>R_Stance_Southpaw</th>\n",
       "      <th>R_Stance_Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.354839</td>\n",
       "      <td>11.322581</td>\n",
       "      <td>6.741935</td>\n",
       "      <td>4.387097</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Winner  title_bout  no_of_rounds  B_current_lose_streak  \\\n",
       "0      1        True             5                    0.0   \n",
       "1      1        True             5                    0.0   \n",
       "2      1       False             3                    0.0   \n",
       "3      0       False             3                    0.0   \n",
       "4      0       False             3                    0.0   \n",
       "\n",
       "   B_current_win_streak  B_draw  B_avg_BODY_att  B_avg_BODY_landed  \\\n",
       "0                   4.0     0.0        9.200000           6.000000   \n",
       "1                   3.0     0.0       14.600000           9.100000   \n",
       "2                   3.0     0.0       15.354839          11.322581   \n",
       "3                   4.0     0.0       17.000000          14.000000   \n",
       "4                   1.0     0.0       17.000000          14.500000   \n",
       "\n",
       "   B_avg_CLINCH_att  B_avg_CLINCH_landed  ...  \\\n",
       "0          0.200000             0.000000  ...   \n",
       "1         11.800000             7.300000  ...   \n",
       "2          6.741935             4.387097  ...   \n",
       "3         13.750000            11.000000  ...   \n",
       "4          2.500000             2.000000  ...   \n",
       "\n",
       "   weight_class_Women's Strawweight  B_Stance_Open Stance  B_Stance_Orthodox  \\\n",
       "0                                 0                     0                  1   \n",
       "1                                 0                     0                  1   \n",
       "2                                 0                     0                  1   \n",
       "3                                 0                     0                  0   \n",
       "4                                 0                     0                  0   \n",
       "\n",
       "   B_Stance_Sideways  B_Stance_Southpaw  B_Stance_Switch  \\\n",
       "0                  0                  0                0   \n",
       "1                  0                  0                0   \n",
       "2                  0                  0                0   \n",
       "3                  0                  0                1   \n",
       "4                  0                  1                0   \n",
       "\n",
       "   R_Stance_Open Stance  R_Stance_Orthodox  R_Stance_Southpaw  R_Stance_Switch  \n",
       "0                     0                  1                  0                0  \n",
       "1                     0                  0                  1                0  \n",
       "2                     0                  1                  0                0  \n",
       "3                     0                  1                  0                0  \n",
       "4                     0                  0                  1                0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for proper dimensions of predictors, target and the encoding of title_bout\n",
    "print(\"X Dimension: \",X.shape)\n",
    "print()\n",
    "print(\"y Dimension: \",y.shape)\n",
    "print()\n",
    "print(\"First row title bout value: 1 is True, 0 is False ==> \",X[0,0])\n",
    "print(\"First row corner value: 1 is Red, 0 is Blue ==> \",y[3])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that we have properly encoded the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras for ANN\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/allankim/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#ANN Model\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu', input_dim = 159))\n",
    "classifier.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1,init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "#compiling the model\n",
    "classifier.compile(optimizer = 'adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/allankim/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "2873/2873 [==============================] - 0s 154us/step - loss: 0.6912 - accuracy: 0.6502\n",
      "Epoch 2/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6850 - accuracy: 0.6700\n",
      "Epoch 3/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6758 - accuracy: 0.6700\n",
      "Epoch 4/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6614 - accuracy: 0.6700\n",
      "Epoch 5/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6416 - accuracy: 0.6700\n",
      "Epoch 6/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6202 - accuracy: 0.6700\n",
      "Epoch 7/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6024 - accuracy: 0.6700\n",
      "Epoch 8/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5941 - accuracy: 0.6700\n",
      "Epoch 9/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5924 - accuracy: 0.6700\n",
      "Epoch 10/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5884 - accuracy: 0.6700\n",
      "Epoch 11/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5832 - accuracy: 0.6700\n",
      "Epoch 12/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5785 - accuracy: 0.6700\n",
      "Epoch 13/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5751 - accuracy: 0.6700\n",
      "Epoch 14/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5725 - accuracy: 0.6700\n",
      "Epoch 15/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5701 - accuracy: 0.6700\n",
      "Epoch 16/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5673 - accuracy: 0.6700\n",
      "Epoch 17/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5646 - accuracy: 0.6700\n",
      "Epoch 18/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5619 - accuracy: 0.6700\n",
      "Epoch 19/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5592 - accuracy: 0.6711\n",
      "Epoch 20/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5562 - accuracy: 0.6780\n",
      "Epoch 21/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5534 - accuracy: 0.6850\n",
      "Epoch 22/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5506 - accuracy: 0.6906\n",
      "Epoch 23/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5477 - accuracy: 0.6979\n",
      "Epoch 24/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5446 - accuracy: 0.7038\n",
      "Epoch 25/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5412 - accuracy: 0.7076\n",
      "Epoch 26/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5379 - accuracy: 0.7125\n",
      "Epoch 27/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5346 - accuracy: 0.7202\n",
      "Epoch 28/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5312 - accuracy: 0.7243\n",
      "Epoch 29/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5279 - accuracy: 0.7289\n",
      "Epoch 30/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5251 - accuracy: 0.7289\n",
      "Epoch 31/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5217 - accuracy: 0.7316\n",
      "Epoch 32/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5176 - accuracy: 0.7365\n",
      "Epoch 33/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5143 - accuracy: 0.7393\n",
      "Epoch 34/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5108 - accuracy: 0.7442\n",
      "Epoch 35/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5075 - accuracy: 0.7470\n",
      "Epoch 36/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5038 - accuracy: 0.7543\n",
      "Epoch 37/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5009 - accuracy: 0.7539\n",
      "Epoch 38/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.4981 - accuracy: 0.7557\n",
      "Epoch 39/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4944 - accuracy: 0.7595\n",
      "Epoch 40/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4918 - accuracy: 0.7598\n",
      "Epoch 41/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4875 - accuracy: 0.7560\n",
      "Epoch 42/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4853 - accuracy: 0.7651\n",
      "Epoch 43/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4819 - accuracy: 0.7661\n",
      "Epoch 44/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4782 - accuracy: 0.7654\n",
      "Epoch 45/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4747 - accuracy: 0.7699\n",
      "Epoch 46/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4700 - accuracy: 0.7741\n",
      "Epoch 47/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4688 - accuracy: 0.7772\n",
      "Epoch 48/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4628 - accuracy: 0.7821\n",
      "Epoch 49/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4602 - accuracy: 0.7779\n",
      "Epoch 50/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4546 - accuracy: 0.7849\n",
      "Epoch 51/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4512 - accuracy: 0.7936\n",
      "Epoch 52/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4456 - accuracy: 0.7974\n",
      "Epoch 53/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4425 - accuracy: 0.7978\n",
      "Epoch 54/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4358 - accuracy: 0.8023\n",
      "Epoch 55/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4316 - accuracy: 0.8054\n",
      "Epoch 56/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4260 - accuracy: 0.8054\n",
      "Epoch 57/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4204 - accuracy: 0.8072\n",
      "Epoch 58/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4160 - accuracy: 0.8131\n",
      "Epoch 59/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4109 - accuracy: 0.8162\n",
      "Epoch 60/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.4069 - accuracy: 0.8197\n",
      "Epoch 61/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4021 - accuracy: 0.8239\n",
      "Epoch 62/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3927 - accuracy: 0.8267\n",
      "Epoch 63/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3869 - accuracy: 0.8357\n",
      "Epoch 64/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3793 - accuracy: 0.8434\n",
      "Epoch 65/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3721 - accuracy: 0.8486\n",
      "Epoch 66/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3659 - accuracy: 0.8500\n",
      "Epoch 67/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3592 - accuracy: 0.8535\n",
      "Epoch 68/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3522 - accuracy: 0.8611\n",
      "Epoch 69/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3449 - accuracy: 0.8618\n",
      "Epoch 70/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3389 - accuracy: 0.8656\n",
      "Epoch 71/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3320 - accuracy: 0.8681\n",
      "Epoch 72/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3241 - accuracy: 0.8768\n",
      "Epoch 73/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3193 - accuracy: 0.8775\n",
      "Epoch 74/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3131 - accuracy: 0.8761\n",
      "Epoch 75/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3068 - accuracy: 0.8914\n",
      "Epoch 76/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2968 - accuracy: 0.8911\n",
      "Epoch 77/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.2914 - accuracy: 0.8914\n",
      "Epoch 78/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2822 - accuracy: 0.8987\n",
      "Epoch 79/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2797 - accuracy: 0.8945\n",
      "Epoch 80/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2722 - accuracy: 0.9050\n",
      "Epoch 81/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2653 - accuracy: 0.9046\n",
      "Epoch 82/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2577 - accuracy: 0.9081\n",
      "Epoch 83/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2507 - accuracy: 0.9144\n",
      "Epoch 84/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2464 - accuracy: 0.9144\n",
      "Epoch 85/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2387 - accuracy: 0.9196\n",
      "Epoch 86/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2329 - accuracy: 0.9262\n",
      "Epoch 87/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2276 - accuracy: 0.9283\n",
      "Epoch 88/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2248 - accuracy: 0.9297\n",
      "Epoch 89/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.2144 - accuracy: 0.9314\n",
      "Epoch 90/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2088 - accuracy: 0.9325\n",
      "Epoch 91/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2024 - accuracy: 0.9384\n",
      "Epoch 92/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1968 - accuracy: 0.9433\n",
      "Epoch 93/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1900 - accuracy: 0.9450\n",
      "Epoch 94/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.1870 - accuracy: 0.9450\n",
      "Epoch 95/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1798 - accuracy: 0.9485\n",
      "Epoch 96/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1751 - accuracy: 0.9488\n",
      "Epoch 97/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1687 - accuracy: 0.9520\n",
      "Epoch 98/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1675 - accuracy: 0.9464\n",
      "Epoch 99/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1626 - accuracy: 0.9541\n",
      "Epoch 100/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1539 - accuracy: 0.9568\n"
     ]
    }
   ],
   "source": [
    "pred1 = classifier.fit(X_train, y_train,\n",
    "              batch_size = 900,\n",
    "              nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.691188401516995,\n",
       "  0.6850431682836956,\n",
       "  0.6757837968174688,\n",
       "  0.6614301487663421,\n",
       "  0.6416404054964041,\n",
       "  0.6201655924257982,\n",
       "  0.6024482564937765,\n",
       "  0.5940685516610363,\n",
       "  0.5924342074047345,\n",
       "  0.5883915053192349,\n",
       "  0.5831648094953662,\n",
       "  0.5784644146559755,\n",
       "  0.5751352771167509,\n",
       "  0.5725053031395588,\n",
       "  0.5701315955048524,\n",
       "  0.5673342822861929,\n",
       "  0.5645910699609012,\n",
       "  0.5618786517643489,\n",
       "  0.5591596884881832,\n",
       "  0.5562414294163857,\n",
       "  0.5534207866949525,\n",
       "  0.5506475551842896,\n",
       "  0.5476586472021343,\n",
       "  0.5446328854793213,\n",
       "  0.5412476176465383,\n",
       "  0.5379010833309703,\n",
       "  0.5346065150749546,\n",
       "  0.5311647229521606,\n",
       "  0.5278964055318929,\n",
       "  0.5251219661817541,\n",
       "  0.5216889720406218,\n",
       "  0.5176382374149393,\n",
       "  0.5142939571632229,\n",
       "  0.510754936452199,\n",
       "  0.5074812251642694,\n",
       "  0.5037678767279636,\n",
       "  0.5009169051072924,\n",
       "  0.4980768898078634,\n",
       "  0.49439525162347964,\n",
       "  0.4918380677492578,\n",
       "  0.4874725910250501,\n",
       "  0.4853247158563888,\n",
       "  0.48190090227243254,\n",
       "  0.4782289135468533,\n",
       "  0.4747379659735032,\n",
       "  0.46998739398152334,\n",
       "  0.46877369683999615,\n",
       "  0.46278759097538463,\n",
       "  0.46022835056457295,\n",
       "  0.45456304341253817,\n",
       "  0.45124625596400963,\n",
       "  0.4456446520177653,\n",
       "  0.4425440457922799,\n",
       "  0.43582097711440293,\n",
       "  0.4315618859779698,\n",
       "  0.4260494366905393,\n",
       "  0.4203901552610434,\n",
       "  0.41598754507135194,\n",
       "  0.4108810960375138,\n",
       "  0.4068663699719037,\n",
       "  0.402098060992384,\n",
       "  0.3926877020088339,\n",
       "  0.3868653374891683,\n",
       "  0.3792860814805567,\n",
       "  0.3721040225261352,\n",
       "  0.3659387310228404,\n",
       "  0.3592193341508295,\n",
       "  0.35223572006467907,\n",
       "  0.34486053979981873,\n",
       "  0.3388556376841273,\n",
       "  0.33197130772696526,\n",
       "  0.32406878861408384,\n",
       "  0.3192619011558144,\n",
       "  0.3130602163281791,\n",
       "  0.3067966490268209,\n",
       "  0.29682300084462115,\n",
       "  0.2913516110196331,\n",
       "  0.28220831518010564,\n",
       "  0.2797035590991549,\n",
       "  0.27221916350408004,\n",
       "  0.2652801043100155,\n",
       "  0.2576786851762605,\n",
       "  0.2507291232776111,\n",
       "  0.24637899259698545,\n",
       "  0.23871886454784533,\n",
       "  0.2329321506336264,\n",
       "  0.2275539556686114,\n",
       "  0.22478922054799144,\n",
       "  0.2144268278695132,\n",
       "  0.20880184984667724,\n",
       "  0.20240424273634802,\n",
       "  0.19677791056465363,\n",
       "  0.1899652207744192,\n",
       "  0.18702156696529534,\n",
       "  0.1798450200556879,\n",
       "  0.17505770987577235,\n",
       "  0.168662424042712,\n",
       "  0.1674592843557375,\n",
       "  0.1626249974897586,\n",
       "  0.15392359620782917],\n",
       " 'accuracy': [0.6501914,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6710755,\n",
       "  0.67803687,\n",
       "  0.6849983,\n",
       "  0.6905674,\n",
       "  0.6978768,\n",
       "  0.70379394,\n",
       "  0.7076227,\n",
       "  0.7124956,\n",
       "  0.72015315,\n",
       "  0.72432995,\n",
       "  0.72885484,\n",
       "  0.72885484,\n",
       "  0.7316394,\n",
       "  0.73651236,\n",
       "  0.7392969,\n",
       "  0.74416983,\n",
       "  0.7469544,\n",
       "  0.7542638,\n",
       "  0.7539158,\n",
       "  0.7556561,\n",
       "  0.7594849,\n",
       "  0.7598329,\n",
       "  0.75600415,\n",
       "  0.7650539,\n",
       "  0.76609814,\n",
       "  0.765402,\n",
       "  0.7699269,\n",
       "  0.7741037,\n",
       "  0.77723634,\n",
       "  0.7821093,\n",
       "  0.77793247,\n",
       "  0.7848938,\n",
       "  0.79359555,\n",
       "  0.7974243,\n",
       "  0.79777235,\n",
       "  0.80229723,\n",
       "  0.8054299,\n",
       "  0.8054299,\n",
       "  0.8071702,\n",
       "  0.81308734,\n",
       "  0.81622,\n",
       "  0.81970066,\n",
       "  0.82387745,\n",
       "  0.826662,\n",
       "  0.8357118,\n",
       "  0.8433693,\n",
       "  0.8485903,\n",
       "  0.8499826,\n",
       "  0.8534633,\n",
       "  0.86112076,\n",
       "  0.86181694,\n",
       "  0.86564565,\n",
       "  0.86808217,\n",
       "  0.87678385,\n",
       "  0.87748,\n",
       "  0.8760877,\n",
       "  0.8914027,\n",
       "  0.89105463,\n",
       "  0.8914027,\n",
       "  0.89871216,\n",
       "  0.8945353,\n",
       "  0.9049774,\n",
       "  0.9046293,\n",
       "  0.90810996,\n",
       "  0.91437525,\n",
       "  0.91437525,\n",
       "  0.91959625,\n",
       "  0.9262095,\n",
       "  0.92829794,\n",
       "  0.92969024,\n",
       "  0.9314306,\n",
       "  0.9324748,\n",
       "  0.9383919,\n",
       "  0.9432649,\n",
       "  0.94500524,\n",
       "  0.94500524,\n",
       "  0.9484859,\n",
       "  0.94883394,\n",
       "  0.9519666,\n",
       "  0.9463975,\n",
       "  0.954055,\n",
       "  0.95683956]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extracting CNN Results for Visualization\n",
    "hist_ann = pred1.history\n",
    "loss_values = hist_ann['loss']\n",
    "acc_values = hist_ann['accuracy'] \n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss - 2-Layer ANN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training acc')\n",
    "plt.title('Training and validation accuracy - 2-Layer ANN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "#plt.savefig('fight_pred1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure there is no bias or accident that the training results was really high, K-Fold will be utilize to ensure consistency of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #K-Fold validation model\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function to introduce model training in keras with sklearn k-fold\n",
    "# def build_predictor():\n",
    "#     #ANN Model\n",
    "#     predictor = Sequential()\n",
    "#     predictor.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu', input_dim = 159))\n",
    "#     predictor.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu'))\n",
    "#     predictor.add(Dense(output_dim = 1,init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "#     #compiling the model\n",
    "#     predictor.compile(optimizer = 'adam',\n",
    "#                       loss = 'binary_crossentropy',\n",
    "#                       metrics = ['accuracy'])\n",
    "#     return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_sk = KerasClassifier(build_fn = build_predictor, batch_size = 900, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = cross_val_score(estimator = classifier_sk,\n",
    "#                              X = X_train,\n",
    "#                              y = y_train,\n",
    "#                              cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1,11),accuracies)\n",
    "# plt.xlabel('Fold Iteration')\n",
    "# plt.title(\"K-Fold Cross Validation Accuracy\")\n",
    "# #plt.savefig(\"ann_k_fold.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch validation model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to introduce model training in keras with Gridsearch\n",
    "def build_classifier(optimizer):\n",
    "    #ANN Model\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu', input_dim = 159))\n",
    "    classifier.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim = 1,init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    #compiling the model\n",
    "    classifier.compile(optimizer = optimizer,\n",
    "                      loss = 'binary_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_sk = KerasClassifier(build_fn = build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for GridSearch\n",
    "params = {'batch_size':[25,32],\n",
    "          'epochs': [100,500],\n",
    "          'optimizer': ['adam','rmsprop']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch for ANN\n",
    "grid_search = GridSearchCV(estimator=classifier_sk,\n",
    "                          param_grid = params,\n",
    "                          scoring='accuracy',\n",
    "                          cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2585/2585 [==============================] - 0s 143us/step - loss: 0.6239 - accuracy: 0.6627\n",
      "Epoch 2/100\n",
      "2585/2585 [==============================] - 0s 110us/step - loss: 0.5767 - accuracy: 0.6723\n",
      "Epoch 3/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 0.5631 - accuracy: 0.6801\n",
      "Epoch 4/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 0.5483 - accuracy: 0.7141\n",
      "Epoch 5/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 0.5321 - accuracy: 0.7319\n",
      "Epoch 6/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 0.5119 - accuracy: 0.7455\n",
      "Epoch 7/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 0.4948 - accuracy: 0.7644\n",
      "Epoch 8/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 0.4773 - accuracy: 0.7830\n",
      "Epoch 9/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 0.4541 - accuracy: 0.7954\n",
      "Epoch 10/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 0.4366 - accuracy: 0.8085\n",
      "Epoch 11/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 0.4083 - accuracy: 0.8217\n",
      "Epoch 12/100\n",
      "2585/2585 [==============================] - 0s 94us/step - loss: 0.3772 - accuracy: 0.8391\n",
      "Epoch 13/100\n",
      "2585/2585 [==============================] - 0s 97us/step - loss: 0.3473 - accuracy: 0.8507\n",
      "Epoch 14/100\n",
      "2585/2585 [==============================] - 0s 94us/step - loss: 0.3197 - accuracy: 0.8658\n",
      "Epoch 15/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 0.2897 - accuracy: 0.8828\n",
      "Epoch 16/100\n",
      "2585/2585 [==============================] - 0s 109us/step - loss: 0.2635 - accuracy: 0.8956\n",
      "Epoch 17/100\n",
      "2585/2585 [==============================] - 0s 109us/step - loss: 0.2380 - accuracy: 0.9064\n",
      "Epoch 18/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 0.2059 - accuracy: 0.9253\n",
      "Epoch 19/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.1885 - accuracy: 0.9304\n",
      "Epoch 20/100\n",
      "2585/2585 [==============================] - 0s 111us/step - loss: 0.1614 - accuracy: 0.9443\n",
      "Epoch 21/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 0.1433 - accuracy: 0.9528\n",
      "Epoch 22/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 0.1228 - accuracy: 0.9621\n",
      "Epoch 23/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 0.1039 - accuracy: 0.9679\n",
      "Epoch 24/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 0.0914 - accuracy: 0.9764\n",
      "Epoch 25/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 0.0733 - accuracy: 0.9799\n",
      "Epoch 26/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 0.0742 - accuracy: 0.9772\n",
      "Epoch 27/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 0.0713 - accuracy: 0.9810\n",
      "Epoch 28/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 0.0733 - accuracy: 0.9776\n",
      "Epoch 29/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 0.0572 - accuracy: 0.9865\n",
      "Epoch 30/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 0.0318 - accuracy: 0.9981\n",
      "Epoch 31/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 0.0227 - accuracy: 0.9985\n",
      "Epoch 32/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 0.0142 - accuracy: 0.9988\n",
      "Epoch 35/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "2585/2585 [==============================] - 0s 109us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "2585/2585 [==============================] - 0s 96us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "2585/2585 [==============================] - 0s 94us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2585/2585 [==============================] - 0s 97us/step - loss: 9.6050e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 8.9491e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 8.1733e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "2585/2585 [==============================] - 0s 96us/step - loss: 7.5693e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "2585/2585 [==============================] - 0s 95us/step - loss: 6.9589e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 6.4330e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 6.0503e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "2585/2585 [==============================] - 0s 95us/step - loss: 5.5701e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 5.1390e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 4.8748e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 4.5163e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 4.1787e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 3.9001e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 3.6269e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 3.3588e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 3.1854e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 2.9059e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 2.7167e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 2.5282e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "2585/2585 [==============================] - 0s 96us/step - loss: 2.3476e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 2.1919e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 2.0685e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 1.9253e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 1.8056e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 1.6884e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 1.5764e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 1.4798e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 1.3785e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 1.3090e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 1.2109e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 1.1304e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 1.0658e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "2585/2585 [==============================] - 0s 109us/step - loss: 9.9288e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 9.3307e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "2585/2585 [==============================] - 0s 97us/step - loss: 8.7318e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "2585/2585 [==============================] - 0s 100us/step - loss: 8.1600e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 7.6268e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 7.2182e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 6.7399e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 6.4274e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "2585/2585 [==============================] - 0s 99us/step - loss: 5.9845e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "2585/2585 [==============================] - 0s 96us/step - loss: 5.6221e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 5.2793e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "2585/2585 [==============================] - 0s 98us/step - loss: 4.9195e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "2585/2585 [==============================] - 0s 94us/step - loss: 4.5982e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2a6a95ca35ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#training for gridsearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# grid =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# best_params = grid.best_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# best_accuracy = grid.best_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \"\"\"\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 97\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown is not supported"
     ]
    }
   ],
   "source": [
    "#training for gridsearch\n",
    "grid = grid_search.fit(X_train,y_train)\n",
    "best_params = grid.best_params_\n",
    "best_accuracy = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd00f8c1748>,\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'batch_size': [25, 32], 'epochs': [100, 500],\n",
       "                         'optimizer': ['adam', 'rmsprop']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
