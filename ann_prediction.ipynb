{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>title_bout</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_avg_BODY_att</th>\n",
       "      <th>B_avg_BODY_landed</th>\n",
       "      <th>B_avg_CLINCH_att</th>\n",
       "      <th>B_avg_CLINCH_landed</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_class_Women's Strawweight</th>\n",
       "      <th>B_Stance_Open Stance</th>\n",
       "      <th>B_Stance_Orthodox</th>\n",
       "      <th>B_Stance_Sideways</th>\n",
       "      <th>B_Stance_Southpaw</th>\n",
       "      <th>B_Stance_Switch</th>\n",
       "      <th>R_Stance_Open Stance</th>\n",
       "      <th>R_Stance_Orthodox</th>\n",
       "      <th>R_Stance_Southpaw</th>\n",
       "      <th>R_Stance_Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.354839</td>\n",
       "      <td>11.322581</td>\n",
       "      <td>6.741935</td>\n",
       "      <td>4.387097</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Winner  title_bout  no_of_rounds  B_current_lose_streak  \\\n",
       "0    Red        True             5                    0.0   \n",
       "1    Red        True             5                    0.0   \n",
       "2    Red       False             3                    0.0   \n",
       "3   Blue       False             3                    0.0   \n",
       "4   Blue       False             3                    0.0   \n",
       "\n",
       "   B_current_win_streak  B_draw  B_avg_BODY_att  B_avg_BODY_landed  \\\n",
       "0                   4.0     0.0        9.200000           6.000000   \n",
       "1                   3.0     0.0       14.600000           9.100000   \n",
       "2                   3.0     0.0       15.354839          11.322581   \n",
       "3                   4.0     0.0       17.000000          14.000000   \n",
       "4                   1.0     0.0       17.000000          14.500000   \n",
       "\n",
       "   B_avg_CLINCH_att  B_avg_CLINCH_landed  ...  \\\n",
       "0          0.200000             0.000000  ...   \n",
       "1         11.800000             7.300000  ...   \n",
       "2          6.741935             4.387097  ...   \n",
       "3         13.750000            11.000000  ...   \n",
       "4          2.500000             2.000000  ...   \n",
       "\n",
       "   weight_class_Women's Strawweight  B_Stance_Open Stance  B_Stance_Orthodox  \\\n",
       "0                                 0                     0                  1   \n",
       "1                                 0                     0                  1   \n",
       "2                                 0                     0                  1   \n",
       "3                                 0                     0                  0   \n",
       "4                                 0                     0                  0   \n",
       "\n",
       "   B_Stance_Sideways  B_Stance_Southpaw  B_Stance_Switch  \\\n",
       "0                  0                  0                0   \n",
       "1                  0                  0                0   \n",
       "2                  0                  0                0   \n",
       "3                  0                  0                1   \n",
       "4                  0                  1                0   \n",
       "\n",
       "   R_Stance_Open Stance  R_Stance_Orthodox  R_Stance_Southpaw  R_Stance_Switch  \n",
       "0                     0                  1                  0                0  \n",
       "1                     0                  0                  1                0  \n",
       "2                     0                  1                  0                0  \n",
       "3                     0                  1                  0                0  \n",
       "4                     0                  0                  1                0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ufcdata/preprocessed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partitioning the dataset to X as predictors, and y as target\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3592 entries, 0 to 3591\n",
      "Columns: 160 entries, Winner to R_Stance_Switch\n",
      "dtypes: bool(1), float64(134), int64(24), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that there are two non-numeric features, winner and title_bout. The winner will be used as taget but the title bout will remain as a predictor and will be encoded with dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the title_bout feature\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X_1.fit_transform(X[:, 0])\n",
    "\n",
    "\n",
    "#Encoding Y\n",
    "labelencoder_y = LabelEncoder()\n",
    "y[:] = labelencoder_y.fit_transform(y[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Dimension:  (3592, 159)\n",
      "\n",
      "y Dimension:  (3592,)\n",
      "\n",
      "First row title bout value: 1 is True, 0 is False ==>  1\n",
      "First row corner value: 1 is Red, 0 is Blue ==>  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>title_bout</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_avg_BODY_att</th>\n",
       "      <th>B_avg_BODY_landed</th>\n",
       "      <th>B_avg_CLINCH_att</th>\n",
       "      <th>B_avg_CLINCH_landed</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_class_Women's Strawweight</th>\n",
       "      <th>B_Stance_Open Stance</th>\n",
       "      <th>B_Stance_Orthodox</th>\n",
       "      <th>B_Stance_Sideways</th>\n",
       "      <th>B_Stance_Southpaw</th>\n",
       "      <th>B_Stance_Switch</th>\n",
       "      <th>R_Stance_Open Stance</th>\n",
       "      <th>R_Stance_Orthodox</th>\n",
       "      <th>R_Stance_Southpaw</th>\n",
       "      <th>R_Stance_Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.354839</td>\n",
       "      <td>11.322581</td>\n",
       "      <td>6.741935</td>\n",
       "      <td>4.387097</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Winner  title_bout  no_of_rounds  B_current_lose_streak  \\\n",
       "0      1        True             5                    0.0   \n",
       "1      1        True             5                    0.0   \n",
       "2      1       False             3                    0.0   \n",
       "3      0       False             3                    0.0   \n",
       "4      0       False             3                    0.0   \n",
       "\n",
       "   B_current_win_streak  B_draw  B_avg_BODY_att  B_avg_BODY_landed  \\\n",
       "0                   4.0     0.0        9.200000           6.000000   \n",
       "1                   3.0     0.0       14.600000           9.100000   \n",
       "2                   3.0     0.0       15.354839          11.322581   \n",
       "3                   4.0     0.0       17.000000          14.000000   \n",
       "4                   1.0     0.0       17.000000          14.500000   \n",
       "\n",
       "   B_avg_CLINCH_att  B_avg_CLINCH_landed  ...  \\\n",
       "0          0.200000             0.000000  ...   \n",
       "1         11.800000             7.300000  ...   \n",
       "2          6.741935             4.387097  ...   \n",
       "3         13.750000            11.000000  ...   \n",
       "4          2.500000             2.000000  ...   \n",
       "\n",
       "   weight_class_Women's Strawweight  B_Stance_Open Stance  B_Stance_Orthodox  \\\n",
       "0                                 0                     0                  1   \n",
       "1                                 0                     0                  1   \n",
       "2                                 0                     0                  1   \n",
       "3                                 0                     0                  0   \n",
       "4                                 0                     0                  0   \n",
       "\n",
       "   B_Stance_Sideways  B_Stance_Southpaw  B_Stance_Switch  \\\n",
       "0                  0                  0                0   \n",
       "1                  0                  0                0   \n",
       "2                  0                  0                0   \n",
       "3                  0                  0                1   \n",
       "4                  0                  1                0   \n",
       "\n",
       "   R_Stance_Open Stance  R_Stance_Orthodox  R_Stance_Southpaw  R_Stance_Switch  \n",
       "0                     0                  1                  0                0  \n",
       "1                     0                  0                  1                0  \n",
       "2                     0                  1                  0                0  \n",
       "3                     0                  1                  0                0  \n",
       "4                     0                  0                  1                0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for proper dimensions of predictors, target and the encoding of title_bout\n",
    "print(\"X Dimension: \",X.shape)\n",
    "print()\n",
    "print(\"y Dimension: \",y.shape)\n",
    "print()\n",
    "print(\"First row title bout value: 1 is True, 0 is False ==> \",X[0,0])\n",
    "print(\"First row corner value: 1 is Red, 0 is Blue ==> \",y[3])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that we have properly encoded the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras for ANN\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/allankim/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#ANN Model\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu', input_dim = 159))\n",
    "classifier.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1,init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "#compiling the model\n",
    "classifier.compile(optimizer = 'adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/allankim/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "2873/2873 [==============================] - 0s 92us/step - loss: 0.6932 - accuracy: 0.5071\n",
      "Epoch 2/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6874 - accuracy: 0.6700\n",
      "Epoch 3/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6803 - accuracy: 0.6700\n",
      "Epoch 4/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6687 - accuracy: 0.6700\n",
      "Epoch 5/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6518 - accuracy: 0.6700\n",
      "Epoch 6/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6298 - accuracy: 0.6700\n",
      "Epoch 7/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.6092 - accuracy: 0.6700\n",
      "Epoch 8/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5957 - accuracy: 0.6700\n",
      "Epoch 9/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5932 - accuracy: 0.6700\n",
      "Epoch 10/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5912 - accuracy: 0.6700\n",
      "Epoch 11/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5850 - accuracy: 0.6700\n",
      "Epoch 12/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5789 - accuracy: 0.6700\n",
      "Epoch 13/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5748 - accuracy: 0.6700\n",
      "Epoch 14/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5728 - accuracy: 0.6700\n",
      "Epoch 15/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5703 - accuracy: 0.6700\n",
      "Epoch 16/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5671 - accuracy: 0.6700\n",
      "Epoch 17/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5640 - accuracy: 0.6700\n",
      "Epoch 18/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5616 - accuracy: 0.6700\n",
      "Epoch 19/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5592 - accuracy: 0.6700\n",
      "Epoch 20/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5566 - accuracy: 0.6704\n",
      "Epoch 21/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5541 - accuracy: 0.6735\n",
      "Epoch 22/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5514 - accuracy: 0.6787\n",
      "Epoch 23/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5486 - accuracy: 0.6871\n",
      "Epoch 24/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5459 - accuracy: 0.6965\n",
      "Epoch 25/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5430 - accuracy: 0.7007\n",
      "Epoch 26/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5406 - accuracy: 0.7045\n",
      "Epoch 27/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5377 - accuracy: 0.7076\n",
      "Epoch 28/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5346 - accuracy: 0.7146\n",
      "Epoch 29/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5313 - accuracy: 0.7195\n",
      "Epoch 30/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5285 - accuracy: 0.7247\n",
      "Epoch 31/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5254 - accuracy: 0.7278\n",
      "Epoch 32/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.5224 - accuracy: 0.7320\n",
      "Epoch 33/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5187 - accuracy: 0.7358\n",
      "Epoch 34/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5157 - accuracy: 0.7362\n",
      "Epoch 35/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5133 - accuracy: 0.7369\n",
      "Epoch 36/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5099 - accuracy: 0.7417\n",
      "Epoch 37/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5064 - accuracy: 0.7442\n",
      "Epoch 38/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5031 - accuracy: 0.7518\n",
      "Epoch 39/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.5007 - accuracy: 0.7539\n",
      "Epoch 40/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4971 - accuracy: 0.7567\n",
      "Epoch 41/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4951 - accuracy: 0.7522\n",
      "Epoch 42/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4902 - accuracy: 0.7546\n",
      "Epoch 43/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4887 - accuracy: 0.7588\n",
      "Epoch 44/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4858 - accuracy: 0.7633\n",
      "Epoch 45/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4818 - accuracy: 0.7713\n",
      "Epoch 46/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.4783 - accuracy: 0.7689\n",
      "Epoch 47/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4751 - accuracy: 0.7703\n",
      "Epoch 48/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4725 - accuracy: 0.7741\n",
      "Epoch 49/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4677 - accuracy: 0.7790\n",
      "Epoch 50/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4642 - accuracy: 0.7793\n",
      "Epoch 51/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4597 - accuracy: 0.7870\n",
      "Epoch 52/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4577 - accuracy: 0.7835\n",
      "Epoch 53/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4523 - accuracy: 0.7887\n",
      "Epoch 54/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4479 - accuracy: 0.7891\n",
      "Epoch 55/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4436 - accuracy: 0.7936\n",
      "Epoch 56/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4396 - accuracy: 0.7971\n",
      "Epoch 57/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4343 - accuracy: 0.8019\n",
      "Epoch 58/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4298 - accuracy: 0.8120\n",
      "Epoch 59/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4247 - accuracy: 0.8107\n",
      "Epoch 60/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4191 - accuracy: 0.8086\n",
      "Epoch 61/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4147 - accuracy: 0.8169\n",
      "Epoch 62/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4082 - accuracy: 0.8207\n",
      "Epoch 63/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.4037 - accuracy: 0.8277\n",
      "Epoch 64/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3976 - accuracy: 0.8284\n",
      "Epoch 65/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3923 - accuracy: 0.8336\n",
      "Epoch 66/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3859 - accuracy: 0.8371\n",
      "Epoch 67/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3783 - accuracy: 0.8437\n",
      "Epoch 68/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3718 - accuracy: 0.8528\n",
      "Epoch 69/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3647 - accuracy: 0.8486\n",
      "Epoch 70/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3581 - accuracy: 0.8556\n",
      "Epoch 71/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3515 - accuracy: 0.8629\n",
      "Epoch 72/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3433 - accuracy: 0.8674\n",
      "Epoch 73/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3370 - accuracy: 0.8660\n",
      "Epoch 74/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3291 - accuracy: 0.8740\n",
      "Epoch 75/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3213 - accuracy: 0.8806\n",
      "Epoch 76/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.3145 - accuracy: 0.8830\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.3063 - accuracy: 0.8886\n",
      "Epoch 78/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2983 - accuracy: 0.8914\n",
      "Epoch 79/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2926 - accuracy: 0.8949\n",
      "Epoch 80/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2842 - accuracy: 0.8984\n",
      "Epoch 81/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2784 - accuracy: 0.9015\n",
      "Epoch 82/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2690 - accuracy: 0.9078\n",
      "Epoch 83/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2639 - accuracy: 0.9092\n",
      "Epoch 84/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2582 - accuracy: 0.9109\n",
      "Epoch 85/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2544 - accuracy: 0.9109\n",
      "Epoch 86/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2449 - accuracy: 0.9161\n",
      "Epoch 87/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2354 - accuracy: 0.9262\n",
      "Epoch 88/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2305 - accuracy: 0.9238\n",
      "Epoch 89/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2228 - accuracy: 0.9335\n",
      "Epoch 90/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2180 - accuracy: 0.9311\n",
      "Epoch 91/100\n",
      "2873/2873 [==============================] - 0s 4us/step - loss: 0.2121 - accuracy: 0.9353\n",
      "Epoch 92/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2055 - accuracy: 0.9391\n",
      "Epoch 93/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.2023 - accuracy: 0.9398\n",
      "Epoch 94/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1912 - accuracy: 0.9481\n",
      "Epoch 95/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1870 - accuracy: 0.9509\n",
      "Epoch 96/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1792 - accuracy: 0.9492\n",
      "Epoch 97/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1770 - accuracy: 0.9485\n",
      "Epoch 98/100\n",
      "2873/2873 [==============================] - 0s 6us/step - loss: 0.1681 - accuracy: 0.9541\n",
      "Epoch 99/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1661 - accuracy: 0.9548\n",
      "Epoch 100/100\n",
      "2873/2873 [==============================] - 0s 5us/step - loss: 0.1611 - accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "pred1 = classifier.fit(X_train, y_train,\n",
    "              batch_size = 900,\n",
    "              nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6931802733534519,\n",
       "  0.6874171415978594,\n",
       "  0.68031387332421,\n",
       "  0.6686502001528701,\n",
       "  0.6517814411919498,\n",
       "  0.6298097644041442,\n",
       "  0.6091665799427729,\n",
       "  0.5956606331329665,\n",
       "  0.5932458427530773,\n",
       "  0.5911762737829511,\n",
       "  0.5850073469668533,\n",
       "  0.5789013353325206,\n",
       "  0.5747695316473367,\n",
       "  0.5727957618431558,\n",
       "  0.5702722401640534,\n",
       "  0.5670500429424309,\n",
       "  0.5639634553746318,\n",
       "  0.5615724500902762,\n",
       "  0.5591700885962245,\n",
       "  0.5565579883155198,\n",
       "  0.55410696667244,\n",
       "  0.5514245136789109,\n",
       "  0.5486420708336649,\n",
       "  0.5459121220667023,\n",
       "  0.5429685867977939,\n",
       "  0.5405656725033376,\n",
       "  0.5377437702421938,\n",
       "  0.5346481492201542,\n",
       "  0.5312615607077761,\n",
       "  0.5284856522369584,\n",
       "  0.525381481921345,\n",
       "  0.5224407854662761,\n",
       "  0.5186871549330478,\n",
       "  0.5157047252475779,\n",
       "  0.5132562753799855,\n",
       "  0.5098710805955682,\n",
       "  0.5063740262016784,\n",
       "  0.5030747041484848,\n",
       "  0.5006550906470458,\n",
       "  0.49708422155401827,\n",
       "  0.4950664578478302,\n",
       "  0.4901748939523953,\n",
       "  0.4887198922819183,\n",
       "  0.48579470562760607,\n",
       "  0.48183787196843497,\n",
       "  0.47830876856368054,\n",
       "  0.475096434780085,\n",
       "  0.4725165070451762,\n",
       "  0.46771322843757107,\n",
       "  0.4641851530936467,\n",
       "  0.4596717922147292,\n",
       "  0.4576963364787522,\n",
       "  0.45229412763117915,\n",
       "  0.44789350193591637,\n",
       "  0.44364990581837094,\n",
       "  0.4396330753955283,\n",
       "  0.43430325914831724,\n",
       "  0.42984949739561074,\n",
       "  0.4247380350987089,\n",
       "  0.4190835265842747,\n",
       "  0.4147457090189264,\n",
       "  0.4082212727886436,\n",
       "  0.40365324041547157,\n",
       "  0.3976473082680342,\n",
       "  0.3922971714841668,\n",
       "  0.38594498029163476,\n",
       "  0.37829051767124183,\n",
       "  0.3718499749473608,\n",
       "  0.36471548088328,\n",
       "  0.3580821185858043,\n",
       "  0.35151163676122815,\n",
       "  0.343293013076437,\n",
       "  0.33700607444739616,\n",
       "  0.3290982242145897,\n",
       "  0.3213015400052195,\n",
       "  0.3145255002459291,\n",
       "  0.3062924552557156,\n",
       "  0.298276595815399,\n",
       "  0.29262256396177794,\n",
       "  0.28415716779468536,\n",
       "  0.2783687450601131,\n",
       "  0.2689744270961956,\n",
       "  0.26392528160581846,\n",
       "  0.25821758305159254,\n",
       "  0.25443662045892423,\n",
       "  0.24487740714770762,\n",
       "  0.23536664126145893,\n",
       "  0.23047580057803738,\n",
       "  0.222801313079113,\n",
       "  0.21800954296038702,\n",
       "  0.21205122494506704,\n",
       "  0.2055117562231684,\n",
       "  0.20232718309541217,\n",
       "  0.19117656174828024,\n",
       "  0.1870073939019116,\n",
       "  0.1791830798743952,\n",
       "  0.1770251439686565,\n",
       "  0.16810163989886148,\n",
       "  0.1661104731419922,\n",
       "  0.16110626046681628],\n",
       " 'accuracy': [0.5071354,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6700313,\n",
       "  0.6703794,\n",
       "  0.673512,\n",
       "  0.67873305,\n",
       "  0.68708664,\n",
       "  0.6964845,\n",
       "  0.7006613,\n",
       "  0.70449007,\n",
       "  0.7076227,\n",
       "  0.71458405,\n",
       "  0.71945703,\n",
       "  0.72467804,\n",
       "  0.7278106,\n",
       "  0.7319875,\n",
       "  0.73581624,\n",
       "  0.7361643,\n",
       "  0.73686045,\n",
       "  0.7417334,\n",
       "  0.74416983,\n",
       "  0.75182736,\n",
       "  0.7539158,\n",
       "  0.75670034,\n",
       "  0.75217545,\n",
       "  0.7546119,\n",
       "  0.7587887,\n",
       "  0.7633136,\n",
       "  0.77131915,\n",
       "  0.7688827,\n",
       "  0.770275,\n",
       "  0.7741037,\n",
       "  0.7789767,\n",
       "  0.77932477,\n",
       "  0.78698224,\n",
       "  0.78350157,\n",
       "  0.7887226,\n",
       "  0.78907067,\n",
       "  0.79359555,\n",
       "  0.7970762,\n",
       "  0.8019492,\n",
       "  0.8120432,\n",
       "  0.8106509,\n",
       "  0.80856246,\n",
       "  0.8169161,\n",
       "  0.8207449,\n",
       "  0.8277062,\n",
       "  0.82840234,\n",
       "  0.8336234,\n",
       "  0.8371041,\n",
       "  0.8437174,\n",
       "  0.85276717,\n",
       "  0.8485903,\n",
       "  0.85555166,\n",
       "  0.8628611,\n",
       "  0.867386,\n",
       "  0.86599374,\n",
       "  0.8739993,\n",
       "  0.8806126,\n",
       "  0.8830491,\n",
       "  0.8886182,\n",
       "  0.8914027,\n",
       "  0.8948834,\n",
       "  0.89836407,\n",
       "  0.9014967,\n",
       "  0.90776193,\n",
       "  0.9091542,\n",
       "  0.9108945,\n",
       "  0.9108945,\n",
       "  0.9161156,\n",
       "  0.9262095,\n",
       "  0.92377305,\n",
       "  0.93351895,\n",
       "  0.9310825,\n",
       "  0.9352593,\n",
       "  0.93908805,\n",
       "  0.93978417,\n",
       "  0.9481378,\n",
       "  0.95092237,\n",
       "  0.94918203,\n",
       "  0.9484859,\n",
       "  0.954055,\n",
       "  0.95475113,\n",
       "  0.95579535]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extracting CNN Results for Visualization\n",
    "hist_ann = pred1.history\n",
    "loss_values = hist_ann['loss']\n",
    "acc_values = hist_ann['accuracy'] \n",
    "\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss - 2-Layer ANN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training acc')\n",
    "plt.title('Training and validation accuracy - 2-Layer ANN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "#plt.savefig('fight_pred1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure there is no bias or accident that the training results was really high, K-Fold will be utilize to ensure consistency of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold validation model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to introduce model training in keras with sklearn k-fold\n",
    "def build_predictor():\n",
    "    #ANN Model\n",
    "    predictor = Sequential()\n",
    "    predictor.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu', input_dim = 159))\n",
    "    predictor.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu'))\n",
    "    predictor.add(Dense(output_dim = 1,init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    #compiling the model\n",
    "    predictor.compile(optimizer = 'adam',\n",
    "                      loss = 'binary_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_sk = KerasClassifier(build_fn = build_predictor, batch_size = 900, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2585/2585 [==============================] - 0s 43us/step - loss: 0.6916 - accuracy: 0.6074\n",
      "Epoch 2/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6866 - accuracy: 0.6723\n",
      "Epoch 3/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6804 - accuracy: 0.6723\n",
      "Epoch 4/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6713 - accuracy: 0.6723\n",
      "Epoch 5/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6590 - accuracy: 0.6723\n",
      "Epoch 6/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6431 - accuracy: 0.6723\n",
      "Epoch 7/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6255 - accuracy: 0.6723\n",
      "Epoch 8/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6094 - accuracy: 0.6723\n",
      "Epoch 9/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5980 - accuracy: 0.6723\n",
      "Epoch 10/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5925 - accuracy: 0.6723\n",
      "Epoch 11/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5914 - accuracy: 0.6723\n",
      "Epoch 12/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5880 - accuracy: 0.6723\n",
      "Epoch 13/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5831 - accuracy: 0.6723\n",
      "Epoch 14/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5779 - accuracy: 0.6723\n",
      "Epoch 15/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5742 - accuracy: 0.6723\n",
      "Epoch 16/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5715 - accuracy: 0.6723\n",
      "Epoch 17/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5691 - accuracy: 0.6723\n",
      "Epoch 18/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5665 - accuracy: 0.6723\n",
      "Epoch 19/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5638 - accuracy: 0.6723\n",
      "Epoch 20/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5608 - accuracy: 0.6723\n",
      "Epoch 21/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5582 - accuracy: 0.6723\n",
      "Epoch 22/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5558 - accuracy: 0.6723\n",
      "Epoch 23/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5531 - accuracy: 0.6723\n",
      "Epoch 24/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5508 - accuracy: 0.6723\n",
      "Epoch 25/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5483 - accuracy: 0.6723\n",
      "Epoch 26/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5459 - accuracy: 0.6723\n",
      "Epoch 27/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5435 - accuracy: 0.6723\n",
      "Epoch 28/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5413 - accuracy: 0.6723\n",
      "Epoch 29/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5387 - accuracy: 0.6723\n",
      "Epoch 30/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5363 - accuracy: 0.6816\n",
      "Epoch 31/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5339 - accuracy: 0.6859\n",
      "Epoch 32/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5315 - accuracy: 0.6909\n",
      "Epoch 33/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5289 - accuracy: 0.6952\n",
      "Epoch 34/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5266 - accuracy: 0.7010\n",
      "Epoch 35/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5242 - accuracy: 0.7052\n",
      "Epoch 36/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5214 - accuracy: 0.7106\n",
      "Epoch 37/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5188 - accuracy: 0.7157\n",
      "Epoch 38/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5160 - accuracy: 0.7234\n",
      "Epoch 39/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5129 - accuracy: 0.7300\n",
      "Epoch 40/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5099 - accuracy: 0.7373\n",
      "Epoch 41/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5063 - accuracy: 0.7431\n",
      "Epoch 42/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5028 - accuracy: 0.7505\n",
      "Epoch 43/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4990 - accuracy: 0.7544\n",
      "Epoch 44/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4956 - accuracy: 0.7598\n",
      "Epoch 45/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4912 - accuracy: 0.7632\n",
      "Epoch 46/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4873 - accuracy: 0.7663\n",
      "Epoch 47/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4838 - accuracy: 0.7702\n",
      "Epoch 48/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4792 - accuracy: 0.7741\n",
      "Epoch 49/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4749 - accuracy: 0.7737\n",
      "Epoch 50/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4710 - accuracy: 0.7807\n",
      "Epoch 51/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4660 - accuracy: 0.7868\n",
      "Epoch 52/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4616 - accuracy: 0.7892\n",
      "Epoch 53/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4568 - accuracy: 0.7915\n",
      "Epoch 54/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4519 - accuracy: 0.7946\n",
      "Epoch 55/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4466 - accuracy: 0.7977\n",
      "Epoch 56/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4415 - accuracy: 0.8023\n",
      "Epoch 57/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4354 - accuracy: 0.8050\n",
      "Epoch 58/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4295 - accuracy: 0.8058\n",
      "Epoch 59/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4240 - accuracy: 0.8162\n",
      "Epoch 60/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4163 - accuracy: 0.8193\n",
      "Epoch 61/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4095 - accuracy: 0.8251\n",
      "Epoch 62/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4017 - accuracy: 0.8344\n",
      "Epoch 63/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3938 - accuracy: 0.8371\n",
      "Epoch 64/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3857 - accuracy: 0.8414\n",
      "Epoch 65/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3784 - accuracy: 0.8530\n",
      "Epoch 66/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3679 - accuracy: 0.8553\n",
      "Epoch 67/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3594 - accuracy: 0.8611\n",
      "Epoch 68/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3506 - accuracy: 0.8673\n",
      "Epoch 69/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3402 - accuracy: 0.8727\n",
      "Epoch 70/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3307 - accuracy: 0.8781\n",
      "Epoch 71/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3218 - accuracy: 0.8816\n",
      "Epoch 72/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3116 - accuracy: 0.8847\n",
      "Epoch 73/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3012 - accuracy: 0.8925\n",
      "Epoch 74/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2925 - accuracy: 0.8975\n",
      "Epoch 75/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2822 - accuracy: 0.8998\n",
      "Epoch 76/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2723 - accuracy: 0.9079\n",
      "Epoch 77/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2643 - accuracy: 0.9095\n",
      "Epoch 78/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2531 - accuracy: 0.9191\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2439 - accuracy: 0.9199\n",
      "Epoch 80/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2349 - accuracy: 0.9219\n",
      "Epoch 81/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2248 - accuracy: 0.9338\n",
      "Epoch 82/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2158 - accuracy: 0.9373\n",
      "Epoch 83/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2076 - accuracy: 0.9416\n",
      "Epoch 84/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1994 - accuracy: 0.9455\n",
      "Epoch 85/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1902 - accuracy: 0.9474\n",
      "Epoch 86/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1819 - accuracy: 0.9567\n",
      "Epoch 87/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1737 - accuracy: 0.9598\n",
      "Epoch 88/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1647 - accuracy: 0.9636\n",
      "Epoch 89/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1576 - accuracy: 0.9698\n",
      "Epoch 90/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1512 - accuracy: 0.9725\n",
      "Epoch 91/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1438 - accuracy: 0.9741\n",
      "Epoch 92/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1377 - accuracy: 0.9772\n",
      "Epoch 93/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1311 - accuracy: 0.9783\n",
      "Epoch 94/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1235 - accuracy: 0.9830\n",
      "Epoch 95/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1185 - accuracy: 0.9830\n",
      "Epoch 96/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1121 - accuracy: 0.9841\n",
      "Epoch 97/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1063 - accuracy: 0.9880\n",
      "Epoch 98/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1021 - accuracy: 0.9861\n",
      "Epoch 99/100\n",
      "2585/2585 [==============================] - 0s 9us/step - loss: 0.0969 - accuracy: 0.9911\n",
      "Epoch 100/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.0923 - accuracy: 0.9903\n",
      "288/288 [==============================] - 0s 89us/step\n",
      "Epoch 1/100\n",
      "2585/2585 [==============================] - 0s 42us/step - loss: 0.6912 - accuracy: 0.6313\n",
      "Epoch 2/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6856 - accuracy: 0.6723\n",
      "Epoch 3/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6783 - accuracy: 0.6723\n",
      "Epoch 4/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6682 - accuracy: 0.6723\n",
      "Epoch 5/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6540 - accuracy: 0.6723\n",
      "Epoch 6/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6372 - accuracy: 0.6723\n",
      "Epoch 7/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6190 - accuracy: 0.6723\n",
      "Epoch 8/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.6032 - accuracy: 0.6723\n",
      "Epoch 9/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5938 - accuracy: 0.6723\n",
      "Epoch 10/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5893 - accuracy: 0.6723\n",
      "Epoch 11/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5878 - accuracy: 0.6723\n",
      "Epoch 12/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5840 - accuracy: 0.6723\n",
      "Epoch 13/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5787 - accuracy: 0.6723\n",
      "Epoch 14/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5735 - accuracy: 0.6723\n",
      "Epoch 15/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5699 - accuracy: 0.6723\n",
      "Epoch 16/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5672 - accuracy: 0.6723\n",
      "Epoch 17/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5646 - accuracy: 0.6723\n",
      "Epoch 18/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5617 - accuracy: 0.6723\n",
      "Epoch 19/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5583 - accuracy: 0.6723\n",
      "Epoch 20/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5554 - accuracy: 0.6723\n",
      "Epoch 21/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5523 - accuracy: 0.6743\n",
      "Epoch 22/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5491 - accuracy: 0.6758\n",
      "Epoch 23/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5461 - accuracy: 0.6801\n",
      "Epoch 24/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5427 - accuracy: 0.6839\n",
      "Epoch 25/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5395 - accuracy: 0.6897\n",
      "Epoch 26/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5363 - accuracy: 0.6994\n",
      "Epoch 27/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5328 - accuracy: 0.7025\n",
      "Epoch 28/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5293 - accuracy: 0.7103\n",
      "Epoch 29/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5257 - accuracy: 0.7172\n",
      "Epoch 30/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5221 - accuracy: 0.7242\n",
      "Epoch 31/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5180 - accuracy: 0.7331\n",
      "Epoch 32/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5141 - accuracy: 0.7400\n",
      "Epoch 33/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5098 - accuracy: 0.7447\n",
      "Epoch 34/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5054 - accuracy: 0.7478\n",
      "Epoch 35/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5008 - accuracy: 0.7497\n",
      "Epoch 36/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4959 - accuracy: 0.7578\n",
      "Epoch 37/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4911 - accuracy: 0.7636\n",
      "Epoch 38/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4861 - accuracy: 0.7725\n",
      "Epoch 39/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4810 - accuracy: 0.7760\n",
      "Epoch 40/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4760 - accuracy: 0.7814\n",
      "Epoch 41/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4703 - accuracy: 0.7861\n",
      "Epoch 42/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4650 - accuracy: 0.7926\n",
      "Epoch 43/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4597 - accuracy: 0.7954\n",
      "Epoch 44/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4540 - accuracy: 0.7985\n",
      "Epoch 45/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4486 - accuracy: 0.7988\n",
      "Epoch 46/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4422 - accuracy: 0.7996\n",
      "Epoch 47/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4365 - accuracy: 0.8054\n",
      "Epoch 48/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4304 - accuracy: 0.8085\n",
      "Epoch 49/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4243 - accuracy: 0.8097\n",
      "Epoch 50/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4183 - accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4125 - accuracy: 0.8213\n",
      "Epoch 52/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4058 - accuracy: 0.8244\n",
      "Epoch 53/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3999 - accuracy: 0.8279\n",
      "Epoch 54/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3938 - accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3877 - accuracy: 0.8383\n",
      "Epoch 56/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3813 - accuracy: 0.8391\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3748 - accuracy: 0.8441\n",
      "Epoch 58/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3681 - accuracy: 0.8487\n",
      "Epoch 59/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3623 - accuracy: 0.8518\n",
      "Epoch 60/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3559 - accuracy: 0.8515\n",
      "Epoch 61/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3495 - accuracy: 0.8600\n",
      "Epoch 62/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3435 - accuracy: 0.8615\n",
      "Epoch 63/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3371 - accuracy: 0.8619\n",
      "Epoch 64/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3306 - accuracy: 0.8681\n",
      "Epoch 65/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3243 - accuracy: 0.8731\n",
      "Epoch 66/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3179 - accuracy: 0.8735\n",
      "Epoch 67/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3116 - accuracy: 0.8781\n",
      "Epoch 68/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3047 - accuracy: 0.8812\n",
      "Epoch 69/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2993 - accuracy: 0.8816\n",
      "Epoch 70/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2909 - accuracy: 0.8890\n",
      "Epoch 71/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2859 - accuracy: 0.8956\n",
      "Epoch 72/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2788 - accuracy: 0.8959\n",
      "Epoch 73/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2719 - accuracy: 0.8990\n",
      "Epoch 74/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2652 - accuracy: 0.9064\n",
      "Epoch 75/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2580 - accuracy: 0.9091\n",
      "Epoch 76/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2519 - accuracy: 0.9106\n",
      "Epoch 77/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2437 - accuracy: 0.9172\n",
      "Epoch 78/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2385 - accuracy: 0.9199\n",
      "Epoch 79/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2314 - accuracy: 0.9207\n",
      "Epoch 80/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2245 - accuracy: 0.9280\n",
      "Epoch 81/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2183 - accuracy: 0.9304\n",
      "Epoch 82/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2120 - accuracy: 0.9350\n",
      "Epoch 83/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2057 - accuracy: 0.9381\n",
      "Epoch 84/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1992 - accuracy: 0.9416\n",
      "Epoch 85/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1925 - accuracy: 0.9478\n",
      "Epoch 86/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1873 - accuracy: 0.9462\n",
      "Epoch 87/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1808 - accuracy: 0.9505\n",
      "Epoch 88/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1755 - accuracy: 0.9547\n",
      "Epoch 89/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1707 - accuracy: 0.9540\n",
      "Epoch 90/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1648 - accuracy: 0.9578\n",
      "Epoch 91/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1590 - accuracy: 0.9602\n",
      "Epoch 92/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1543 - accuracy: 0.9605\n",
      "Epoch 93/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1488 - accuracy: 0.9656\n",
      "Epoch 94/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1437 - accuracy: 0.9675\n",
      "Epoch 95/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1384 - accuracy: 0.9706\n",
      "Epoch 96/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1335 - accuracy: 0.9737\n",
      "Epoch 97/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1283 - accuracy: 0.9741\n",
      "Epoch 98/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1241 - accuracy: 0.9756\n",
      "Epoch 99/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1197 - accuracy: 0.9752\n",
      "Epoch 100/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1155 - accuracy: 0.9779\n",
      "288/288 [==============================] - 0s 97us/step\n",
      "Epoch 1/100\n",
      "2585/2585 [==============================] - 0s 43us/step - loss: 0.6919 - accuracy: 0.6104\n",
      "Epoch 2/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6875 - accuracy: 0.6681\n",
      "Epoch 3/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6818 - accuracy: 0.6681\n",
      "Epoch 4/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6737 - accuracy: 0.6681\n",
      "Epoch 5/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6622 - accuracy: 0.6681\n",
      "Epoch 6/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6462 - accuracy: 0.6681\n",
      "Epoch 7/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6278 - accuracy: 0.6681\n",
      "Epoch 8/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.6099 - accuracy: 0.6681\n",
      "Epoch 9/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5968 - accuracy: 0.6681\n",
      "Epoch 10/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5896 - accuracy: 0.6681\n",
      "Epoch 11/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5888 - accuracy: 0.6681\n",
      "Epoch 12/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5859 - accuracy: 0.6681\n",
      "Epoch 13/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5807 - accuracy: 0.6681\n",
      "Epoch 14/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5757 - accuracy: 0.6681\n",
      "Epoch 15/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5717 - accuracy: 0.6681\n",
      "Epoch 16/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5690 - accuracy: 0.6681\n",
      "Epoch 17/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5665 - accuracy: 0.6681\n",
      "Epoch 18/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5639 - accuracy: 0.6681\n",
      "Epoch 19/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5610 - accuracy: 0.6689\n",
      "Epoch 20/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5579 - accuracy: 0.6720\n",
      "Epoch 21/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5550 - accuracy: 0.6774\n",
      "Epoch 22/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5522 - accuracy: 0.6870\n",
      "Epoch 23/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5495 - accuracy: 0.6909\n",
      "Epoch 24/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5466 - accuracy: 0.6952\n",
      "Epoch 25/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5437 - accuracy: 0.7048\n",
      "Epoch 26/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5407 - accuracy: 0.7087\n",
      "Epoch 27/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5376 - accuracy: 0.7180\n",
      "Epoch 28/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5347 - accuracy: 0.7219\n",
      "Epoch 29/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5316 - accuracy: 0.7257\n",
      "Epoch 30/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5283 - accuracy: 0.7296\n",
      "Epoch 31/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5253 - accuracy: 0.7323\n",
      "Epoch 32/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5222 - accuracy: 0.7346\n",
      "Epoch 33/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5186 - accuracy: 0.7369\n",
      "Epoch 34/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5155 - accuracy: 0.7420\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5121 - accuracy: 0.7451\n",
      "Epoch 36/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.5087 - accuracy: 0.7485\n",
      "Epoch 37/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5054 - accuracy: 0.7516\n",
      "Epoch 38/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.5021 - accuracy: 0.7520\n",
      "Epoch 39/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4989 - accuracy: 0.7544\n",
      "Epoch 40/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4953 - accuracy: 0.7586\n",
      "Epoch 41/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4920 - accuracy: 0.7613\n",
      "Epoch 42/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4887 - accuracy: 0.7632\n",
      "Epoch 43/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4851 - accuracy: 0.7617\n",
      "Epoch 44/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4815 - accuracy: 0.7648\n",
      "Epoch 45/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4781 - accuracy: 0.7660\n",
      "Epoch 46/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4744 - accuracy: 0.7660\n",
      "Epoch 47/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4707 - accuracy: 0.7698\n",
      "Epoch 48/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4671 - accuracy: 0.7710\n",
      "Epoch 49/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4630 - accuracy: 0.7737\n",
      "Epoch 50/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4591 - accuracy: 0.7768\n",
      "Epoch 51/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4549 - accuracy: 0.7795\n",
      "Epoch 52/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4507 - accuracy: 0.7865\n",
      "Epoch 53/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4468 - accuracy: 0.7911\n",
      "Epoch 54/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4415 - accuracy: 0.7969\n",
      "Epoch 55/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4371 - accuracy: 0.8012\n",
      "Epoch 56/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4317 - accuracy: 0.8039\n",
      "Epoch 57/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4260 - accuracy: 0.8070\n",
      "Epoch 58/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4205 - accuracy: 0.8155\n",
      "Epoch 59/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4146 - accuracy: 0.8209\n",
      "Epoch 60/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.4084 - accuracy: 0.8240\n",
      "Epoch 61/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.4023 - accuracy: 0.8255\n",
      "Epoch 62/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3975 - accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3892 - accuracy: 0.8364\n",
      "Epoch 64/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3822 - accuracy: 0.8414\n",
      "Epoch 65/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3752 - accuracy: 0.8464\n",
      "Epoch 66/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3671 - accuracy: 0.8518\n",
      "Epoch 67/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3594 - accuracy: 0.8638\n",
      "Epoch 68/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3510 - accuracy: 0.8673\n",
      "Epoch 69/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3425 - accuracy: 0.8731\n",
      "Epoch 70/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3341 - accuracy: 0.8793\n",
      "Epoch 71/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3264 - accuracy: 0.8855\n",
      "Epoch 72/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.3183 - accuracy: 0.8882\n",
      "Epoch 73/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3104 - accuracy: 0.8940\n",
      "Epoch 74/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.3018 - accuracy: 0.8990\n",
      "Epoch 75/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2944 - accuracy: 0.9002\n",
      "Epoch 76/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2863 - accuracy: 0.9072\n",
      "Epoch 77/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2773 - accuracy: 0.9106\n",
      "Epoch 78/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2688 - accuracy: 0.9137\n",
      "Epoch 79/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2621 - accuracy: 0.9168\n",
      "Epoch 80/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2532 - accuracy: 0.9188\n",
      "Epoch 81/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2443 - accuracy: 0.9246\n",
      "Epoch 82/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2384 - accuracy: 0.9277\n",
      "Epoch 83/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2308 - accuracy: 0.9288\n",
      "Epoch 84/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.2238 - accuracy: 0.9366\n",
      "Epoch 85/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2164 - accuracy: 0.9381\n",
      "Epoch 86/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2106 - accuracy: 0.9369\n",
      "Epoch 87/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.2028 - accuracy: 0.9408\n",
      "Epoch 88/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1956 - accuracy: 0.9447\n",
      "Epoch 89/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1872 - accuracy: 0.9505\n",
      "Epoch 90/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1797 - accuracy: 0.9516\n",
      "Epoch 91/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1727 - accuracy: 0.9571\n",
      "Epoch 92/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1654 - accuracy: 0.9632\n",
      "Epoch 93/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1596 - accuracy: 0.9605\n",
      "Epoch 94/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1530 - accuracy: 0.9675\n",
      "Epoch 95/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1468 - accuracy: 0.9714\n",
      "Epoch 96/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1416 - accuracy: 0.9706\n",
      "Epoch 97/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1358 - accuracy: 0.9760\n",
      "Epoch 98/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1308 - accuracy: 0.9741\n",
      "Epoch 99/100\n",
      "2585/2585 [==============================] - 0s 5us/step - loss: 0.1253 - accuracy: 0.9783\n",
      "Epoch 100/100\n",
      "2585/2585 [==============================] - 0s 4us/step - loss: 0.1205 - accuracy: 0.9810\n",
      "288/288 [==============================] - 0s 101us/step\n",
      "Epoch 1/100\n",
      "2586/2586 [==============================] - 0s 44us/step - loss: 0.6907 - accuracy: 0.6558\n",
      "Epoch 2/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6852 - accuracy: 0.6725\n",
      "Epoch 3/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6779 - accuracy: 0.6725\n",
      "Epoch 4/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6682 - accuracy: 0.6725\n",
      "Epoch 5/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6549 - accuracy: 0.6725\n",
      "Epoch 6/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6390 - accuracy: 0.6725\n",
      "Epoch 7/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6225 - accuracy: 0.6725\n",
      "Epoch 8/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6073 - accuracy: 0.6725\n",
      "Epoch 9/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5974 - accuracy: 0.6725\n",
      "Epoch 10/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5932 - accuracy: 0.6725\n",
      "Epoch 11/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5914 - accuracy: 0.6725\n",
      "Epoch 12/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5879 - accuracy: 0.6725\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5831 - accuracy: 0.6725\n",
      "Epoch 14/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5784 - accuracy: 0.6725\n",
      "Epoch 15/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5747 - accuracy: 0.6725\n",
      "Epoch 16/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5719 - accuracy: 0.6725\n",
      "Epoch 17/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5698 - accuracy: 0.6725\n",
      "Epoch 18/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5674 - accuracy: 0.6725\n",
      "Epoch 19/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5647 - accuracy: 0.6725\n",
      "Epoch 20/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5621 - accuracy: 0.6725\n",
      "Epoch 21/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5595 - accuracy: 0.6725\n",
      "Epoch 22/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5572 - accuracy: 0.6725\n",
      "Epoch 23/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5549 - accuracy: 0.6725\n",
      "Epoch 24/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5523 - accuracy: 0.6725\n",
      "Epoch 25/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5499 - accuracy: 0.6725\n",
      "Epoch 26/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5476 - accuracy: 0.6725\n",
      "Epoch 27/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5454 - accuracy: 0.6725\n",
      "Epoch 28/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5430 - accuracy: 0.6725\n",
      "Epoch 29/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5405 - accuracy: 0.6744\n",
      "Epoch 30/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5383 - accuracy: 0.6790\n",
      "Epoch 31/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5358 - accuracy: 0.6860\n",
      "Epoch 32/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5334 - accuracy: 0.6922\n",
      "Epoch 33/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5309 - accuracy: 0.6976\n",
      "Epoch 34/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5285 - accuracy: 0.7034\n",
      "Epoch 35/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5258 - accuracy: 0.7077\n",
      "Epoch 36/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5233 - accuracy: 0.7138\n",
      "Epoch 37/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5204 - accuracy: 0.7212\n",
      "Epoch 38/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5174 - accuracy: 0.7270\n",
      "Epoch 39/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5141 - accuracy: 0.7355\n",
      "Epoch 40/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5106 - accuracy: 0.7425\n",
      "Epoch 41/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5069 - accuracy: 0.7463\n",
      "Epoch 42/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5029 - accuracy: 0.7475\n",
      "Epoch 43/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4988 - accuracy: 0.7517\n",
      "Epoch 44/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4946 - accuracy: 0.7544\n",
      "Epoch 45/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4902 - accuracy: 0.7606\n",
      "Epoch 46/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4859 - accuracy: 0.7641\n",
      "Epoch 47/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4815 - accuracy: 0.7672\n",
      "Epoch 48/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4767 - accuracy: 0.7691\n",
      "Epoch 49/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4718 - accuracy: 0.7746\n",
      "Epoch 50/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4673 - accuracy: 0.7796\n",
      "Epoch 51/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4625 - accuracy: 0.7854\n",
      "Epoch 52/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4575 - accuracy: 0.7881\n",
      "Epoch 53/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4525 - accuracy: 0.7889\n",
      "Epoch 54/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4470 - accuracy: 0.7958\n",
      "Epoch 55/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4420 - accuracy: 0.8005\n",
      "Epoch 56/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4362 - accuracy: 0.8028\n",
      "Epoch 57/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4306 - accuracy: 0.8078\n",
      "Epoch 58/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4250 - accuracy: 0.8132\n",
      "Epoch 59/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4185 - accuracy: 0.8163\n",
      "Epoch 60/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4118 - accuracy: 0.8225\n",
      "Epoch 61/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4050 - accuracy: 0.8275\n",
      "Epoch 62/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3982 - accuracy: 0.8329\n",
      "Epoch 63/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3908 - accuracy: 0.8372\n",
      "Epoch 64/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3832 - accuracy: 0.8430\n",
      "Epoch 65/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3751 - accuracy: 0.8480\n",
      "Epoch 66/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3662 - accuracy: 0.8531\n",
      "Epoch 67/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3573 - accuracy: 0.8585\n",
      "Epoch 68/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3493 - accuracy: 0.8658\n",
      "Epoch 69/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3395 - accuracy: 0.8743\n",
      "Epoch 70/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3304 - accuracy: 0.8794\n",
      "Epoch 71/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3209 - accuracy: 0.8836\n",
      "Epoch 72/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3108 - accuracy: 0.8898\n",
      "Epoch 73/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3013 - accuracy: 0.8971\n",
      "Epoch 74/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2920 - accuracy: 0.8995\n",
      "Epoch 75/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2813 - accuracy: 0.9076\n",
      "Epoch 76/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2715 - accuracy: 0.9111\n",
      "Epoch 77/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2625 - accuracy: 0.9126\n",
      "Epoch 78/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2541 - accuracy: 0.9215\n",
      "Epoch 79/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2441 - accuracy: 0.9234\n",
      "Epoch 80/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2358 - accuracy: 0.9258\n",
      "Epoch 81/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2252 - accuracy: 0.9300\n",
      "Epoch 82/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2182 - accuracy: 0.9323\n",
      "Epoch 83/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2097 - accuracy: 0.9416\n",
      "Epoch 84/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2016 - accuracy: 0.9462\n",
      "Epoch 85/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1935 - accuracy: 0.9482\n",
      "Epoch 86/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1844 - accuracy: 0.9520\n",
      "Epoch 87/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1769 - accuracy: 0.9544\n",
      "Epoch 88/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1690 - accuracy: 0.9606\n",
      "Epoch 89/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1620 - accuracy: 0.9640\n",
      "Epoch 90/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1549 - accuracy: 0.9660\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1480 - accuracy: 0.9706\n",
      "Epoch 92/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1419 - accuracy: 0.9718\n",
      "Epoch 93/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1344 - accuracy: 0.9756\n",
      "Epoch 94/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1289 - accuracy: 0.9768\n",
      "Epoch 95/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1228 - accuracy: 0.9799\n",
      "Epoch 96/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1173 - accuracy: 0.9814\n",
      "Epoch 97/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1116 - accuracy: 0.9830\n",
      "Epoch 98/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1064 - accuracy: 0.9845\n",
      "Epoch 99/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1015 - accuracy: 0.9845\n",
      "Epoch 100/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.0961 - accuracy: 0.9884\n",
      "287/287 [==============================] - 0s 113us/step\n",
      "Epoch 1/100\n",
      "2586/2586 [==============================] - 0s 46us/step - loss: 0.6912 - accuracy: 0.6268\n",
      "Epoch 2/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6858 - accuracy: 0.6674\n",
      "Epoch 3/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6787 - accuracy: 0.6674\n",
      "Epoch 4/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6688 - accuracy: 0.6674\n",
      "Epoch 5/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6567 - accuracy: 0.6674\n",
      "Epoch 6/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6414 - accuracy: 0.6674\n",
      "Epoch 7/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6233 - accuracy: 0.6674\n",
      "Epoch 8/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6086 - accuracy: 0.6674\n",
      "Epoch 9/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5973 - accuracy: 0.6674\n",
      "Epoch 10/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5928 - accuracy: 0.6674\n",
      "Epoch 11/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5909 - accuracy: 0.6674\n",
      "Epoch 12/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5882 - accuracy: 0.6674\n",
      "Epoch 13/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5837 - accuracy: 0.6674\n",
      "Epoch 14/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5787 - accuracy: 0.6674\n",
      "Epoch 15/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5753 - accuracy: 0.6674\n",
      "Epoch 16/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5724 - accuracy: 0.6674\n",
      "Epoch 17/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5701 - accuracy: 0.6674\n",
      "Epoch 18/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5675 - accuracy: 0.6674\n",
      "Epoch 19/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5648 - accuracy: 0.6674\n",
      "Epoch 20/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5620 - accuracy: 0.6678\n",
      "Epoch 21/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5590 - accuracy: 0.6686\n",
      "Epoch 22/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5562 - accuracy: 0.6732\n",
      "Epoch 23/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5537 - accuracy: 0.6802\n",
      "Epoch 24/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5508 - accuracy: 0.6833\n",
      "Epoch 25/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5479 - accuracy: 0.6891\n",
      "Epoch 26/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5449 - accuracy: 0.6988\n",
      "Epoch 27/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5419 - accuracy: 0.7038\n",
      "Epoch 28/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5389 - accuracy: 0.7061\n",
      "Epoch 29/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5356 - accuracy: 0.7135\n",
      "Epoch 30/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5325 - accuracy: 0.7173\n",
      "Epoch 31/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5289 - accuracy: 0.7251\n",
      "Epoch 32/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5254 - accuracy: 0.7305\n",
      "Epoch 33/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5216 - accuracy: 0.7340\n",
      "Epoch 34/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5179 - accuracy: 0.7390\n",
      "Epoch 35/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5140 - accuracy: 0.7436\n",
      "Epoch 36/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5102 - accuracy: 0.7514\n",
      "Epoch 37/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5059 - accuracy: 0.7541\n",
      "Epoch 38/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5018 - accuracy: 0.7587\n",
      "Epoch 39/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4974 - accuracy: 0.7606\n",
      "Epoch 40/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4933 - accuracy: 0.7676\n",
      "Epoch 41/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4890 - accuracy: 0.7699\n",
      "Epoch 42/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4847 - accuracy: 0.7734\n",
      "Epoch 43/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4804 - accuracy: 0.7776\n",
      "Epoch 44/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4756 - accuracy: 0.7804\n",
      "Epoch 45/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4715 - accuracy: 0.7834\n",
      "Epoch 46/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4667 - accuracy: 0.7850\n",
      "Epoch 47/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4623 - accuracy: 0.7865\n",
      "Epoch 48/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4571 - accuracy: 0.7896\n",
      "Epoch 49/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4522 - accuracy: 0.7939\n",
      "Epoch 50/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4476 - accuracy: 0.7970\n",
      "Epoch 51/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4423 - accuracy: 0.8012\n",
      "Epoch 52/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4369 - accuracy: 0.8039\n",
      "Epoch 53/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4315 - accuracy: 0.8074\n",
      "Epoch 54/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4260 - accuracy: 0.8117\n",
      "Epoch 55/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4203 - accuracy: 0.8144\n",
      "Epoch 56/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4160 - accuracy: 0.8155\n",
      "Epoch 57/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4086 - accuracy: 0.8210\n",
      "Epoch 58/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4041 - accuracy: 0.8287\n",
      "Epoch 59/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3984 - accuracy: 0.8264\n",
      "Epoch 60/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3911 - accuracy: 0.8341\n",
      "Epoch 61/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3858 - accuracy: 0.8387\n",
      "Epoch 62/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3773 - accuracy: 0.8465\n",
      "Epoch 63/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3721 - accuracy: 0.8473\n",
      "Epoch 64/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3654 - accuracy: 0.8507\n",
      "Epoch 65/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3576 - accuracy: 0.8619\n",
      "Epoch 66/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3505 - accuracy: 0.8666\n",
      "Epoch 67/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3438 - accuracy: 0.8693\n",
      "Epoch 68/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3366 - accuracy: 0.8751\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3282 - accuracy: 0.8828\n",
      "Epoch 70/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3207 - accuracy: 0.8848\n",
      "Epoch 71/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3122 - accuracy: 0.8886\n",
      "Epoch 72/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3050 - accuracy: 0.8910\n",
      "Epoch 73/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2965 - accuracy: 0.8956\n",
      "Epoch 74/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2898 - accuracy: 0.9006\n",
      "Epoch 75/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2822 - accuracy: 0.9084\n",
      "Epoch 76/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2733 - accuracy: 0.9157\n",
      "Epoch 77/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2657 - accuracy: 0.9149\n",
      "Epoch 78/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2578 - accuracy: 0.9215\n",
      "Epoch 79/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2505 - accuracy: 0.9281\n",
      "Epoch 80/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2424 - accuracy: 0.9308\n",
      "Epoch 81/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2348 - accuracy: 0.9370\n",
      "Epoch 82/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2271 - accuracy: 0.9412\n",
      "Epoch 83/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2204 - accuracy: 0.9420\n",
      "Epoch 84/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2135 - accuracy: 0.9462\n",
      "Epoch 85/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2052 - accuracy: 0.9501\n",
      "Epoch 86/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1980 - accuracy: 0.9528\n",
      "Epoch 87/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1904 - accuracy: 0.9540\n",
      "Epoch 88/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1828 - accuracy: 0.9567\n",
      "Epoch 89/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1755 - accuracy: 0.9598\n",
      "Epoch 90/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1680 - accuracy: 0.9629\n",
      "Epoch 91/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1621 - accuracy: 0.9644\n",
      "Epoch 92/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1553 - accuracy: 0.9691\n",
      "Epoch 93/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1476 - accuracy: 0.9718\n",
      "Epoch 94/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1419 - accuracy: 0.9749\n",
      "Epoch 95/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1348 - accuracy: 0.9768\n",
      "Epoch 96/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1287 - accuracy: 0.9791\n",
      "Epoch 97/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1223 - accuracy: 0.9803\n",
      "Epoch 98/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1164 - accuracy: 0.9826\n",
      "Epoch 99/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1104 - accuracy: 0.9818\n",
      "Epoch 100/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1061 - accuracy: 0.9822\n",
      "287/287 [==============================] - 0s 146us/step\n",
      "Epoch 1/100\n",
      "2586/2586 [==============================] - 0s 48us/step - loss: 0.6921 - accuracy: 0.5654\n",
      "Epoch 2/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6872 - accuracy: 0.6736\n",
      "Epoch 3/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6810 - accuracy: 0.6736\n",
      "Epoch 4/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6718 - accuracy: 0.6736\n",
      "Epoch 5/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6596 - accuracy: 0.6736\n",
      "Epoch 6/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6431 - accuracy: 0.6736\n",
      "Epoch 7/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6242 - accuracy: 0.6736\n",
      "Epoch 8/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6068 - accuracy: 0.6736\n",
      "Epoch 9/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5937 - accuracy: 0.6736\n",
      "Epoch 10/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5861 - accuracy: 0.6736\n",
      "Epoch 11/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5838 - accuracy: 0.6736\n",
      "Epoch 12/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5816 - accuracy: 0.6736\n",
      "Epoch 13/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5773 - accuracy: 0.6736\n",
      "Epoch 14/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5723 - accuracy: 0.6736\n",
      "Epoch 15/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5683 - accuracy: 0.6736\n",
      "Epoch 16/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5654 - accuracy: 0.6736\n",
      "Epoch 17/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5633 - accuracy: 0.6736\n",
      "Epoch 18/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5610 - accuracy: 0.6736\n",
      "Epoch 19/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5584 - accuracy: 0.6736\n",
      "Epoch 20/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5557 - accuracy: 0.6736\n",
      "Epoch 21/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5531 - accuracy: 0.6763\n",
      "Epoch 22/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5505 - accuracy: 0.6810\n",
      "Epoch 23/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5480 - accuracy: 0.6856\n",
      "Epoch 24/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5454 - accuracy: 0.6903\n",
      "Epoch 25/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5429 - accuracy: 0.6964\n",
      "Epoch 26/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5402 - accuracy: 0.7034\n",
      "Epoch 27/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5375 - accuracy: 0.7084\n",
      "Epoch 28/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5347 - accuracy: 0.7135\n",
      "Epoch 29/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5320 - accuracy: 0.7146\n",
      "Epoch 30/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5289 - accuracy: 0.7200\n",
      "Epoch 31/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5258 - accuracy: 0.7196\n",
      "Epoch 32/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5230 - accuracy: 0.7239\n",
      "Epoch 33/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5196 - accuracy: 0.7270\n",
      "Epoch 34/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5163 - accuracy: 0.7305\n",
      "Epoch 35/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5129 - accuracy: 0.7374\n",
      "Epoch 36/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5096 - accuracy: 0.7421\n",
      "Epoch 37/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5060 - accuracy: 0.7456\n",
      "Epoch 38/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5029 - accuracy: 0.7483\n",
      "Epoch 39/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4991 - accuracy: 0.7529\n",
      "Epoch 40/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4954 - accuracy: 0.7568\n",
      "Epoch 41/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4919 - accuracy: 0.7614\n",
      "Epoch 42/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4882 - accuracy: 0.7622\n",
      "Epoch 43/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4848 - accuracy: 0.7672\n",
      "Epoch 44/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4807 - accuracy: 0.7703\n",
      "Epoch 45/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4769 - accuracy: 0.7703\n",
      "Epoch 46/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4726 - accuracy: 0.7757\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4686 - accuracy: 0.7757\n",
      "Epoch 48/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4641 - accuracy: 0.7788\n",
      "Epoch 49/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4599 - accuracy: 0.7819\n",
      "Epoch 50/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4550 - accuracy: 0.7862\n",
      "Epoch 51/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4504 - accuracy: 0.7889\n",
      "Epoch 52/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4455 - accuracy: 0.7935\n",
      "Epoch 53/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4403 - accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4350 - accuracy: 0.8074\n",
      "Epoch 55/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4295 - accuracy: 0.8136\n",
      "Epoch 56/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4239 - accuracy: 0.8125\n",
      "Epoch 57/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4175 - accuracy: 0.8179\n",
      "Epoch 58/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4116 - accuracy: 0.8264\n",
      "Epoch 59/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4050 - accuracy: 0.8310\n",
      "Epoch 60/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3993 - accuracy: 0.8318\n",
      "Epoch 61/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3923 - accuracy: 0.8372\n",
      "Epoch 62/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3865 - accuracy: 0.8407\n",
      "Epoch 63/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3793 - accuracy: 0.8476\n",
      "Epoch 64/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3742 - accuracy: 0.8476\n",
      "Epoch 65/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3659 - accuracy: 0.8554\n",
      "Epoch 66/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3599 - accuracy: 0.8561\n",
      "Epoch 67/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3521 - accuracy: 0.8596\n",
      "Epoch 68/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3457 - accuracy: 0.8670\n",
      "Epoch 69/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3377 - accuracy: 0.8705\n",
      "Epoch 70/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3313 - accuracy: 0.8735\n",
      "Epoch 71/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3238 - accuracy: 0.8774\n",
      "Epoch 72/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3154 - accuracy: 0.8840\n",
      "Epoch 73/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3089 - accuracy: 0.8890\n",
      "Epoch 74/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3028 - accuracy: 0.8929\n",
      "Epoch 75/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2938 - accuracy: 0.8971\n",
      "Epoch 76/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2856 - accuracy: 0.9033\n",
      "Epoch 77/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2792 - accuracy: 0.9045\n",
      "Epoch 78/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2707 - accuracy: 0.9084\n",
      "Epoch 79/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2621 - accuracy: 0.9169\n",
      "Epoch 80/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2559 - accuracy: 0.9176\n",
      "Epoch 81/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2477 - accuracy: 0.9223\n",
      "Epoch 82/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2401 - accuracy: 0.9250\n",
      "Epoch 83/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2325 - accuracy: 0.9281\n",
      "Epoch 84/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2255 - accuracy: 0.9331\n",
      "Epoch 85/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2182 - accuracy: 0.9358\n",
      "Epoch 86/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2111 - accuracy: 0.9381\n",
      "Epoch 87/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2040 - accuracy: 0.9428\n",
      "Epoch 88/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1980 - accuracy: 0.9462\n",
      "Epoch 89/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1927 - accuracy: 0.9482\n",
      "Epoch 90/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1858 - accuracy: 0.9520\n",
      "Epoch 91/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1787 - accuracy: 0.9528\n",
      "Epoch 92/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1740 - accuracy: 0.9559\n",
      "Epoch 93/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1682 - accuracy: 0.9602\n",
      "Epoch 94/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1618 - accuracy: 0.9613\n",
      "Epoch 95/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1566 - accuracy: 0.9652\n",
      "Epoch 96/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1509 - accuracy: 0.9675\n",
      "Epoch 97/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1454 - accuracy: 0.9683\n",
      "Epoch 98/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1410 - accuracy: 0.9714\n",
      "Epoch 99/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1364 - accuracy: 0.9722\n",
      "Epoch 100/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1316 - accuracy: 0.9718\n",
      "287/287 [==============================] - 0s 135us/step\n",
      "Epoch 1/100\n",
      "2586/2586 [==============================] - 0s 48us/step - loss: 0.6888 - accuracy: 0.6659\n",
      "Epoch 2/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6825 - accuracy: 0.6663\n",
      "Epoch 3/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6730 - accuracy: 0.6663\n",
      "Epoch 4/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6604 - accuracy: 0.6663\n",
      "Epoch 5/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6440 - accuracy: 0.6663\n",
      "Epoch 6/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6256 - accuracy: 0.6663\n",
      "Epoch 7/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6084 - accuracy: 0.6663\n",
      "Epoch 8/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5974 - accuracy: 0.6663\n",
      "Epoch 9/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5927 - accuracy: 0.6663\n",
      "Epoch 10/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5916 - accuracy: 0.6663\n",
      "Epoch 11/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5886 - accuracy: 0.6663\n",
      "Epoch 12/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5832 - accuracy: 0.6663\n",
      "Epoch 13/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5783 - accuracy: 0.6663\n",
      "Epoch 14/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5749 - accuracy: 0.6663\n",
      "Epoch 15/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5721 - accuracy: 0.6663\n",
      "Epoch 16/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5698 - accuracy: 0.6663\n",
      "Epoch 17/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5672 - accuracy: 0.6663\n",
      "Epoch 18/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5642 - accuracy: 0.6663\n",
      "Epoch 19/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5615 - accuracy: 0.6663\n",
      "Epoch 20/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5591 - accuracy: 0.6663\n",
      "Epoch 21/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5567 - accuracy: 0.6663\n",
      "Epoch 22/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5544 - accuracy: 0.6663\n",
      "Epoch 23/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5519 - accuracy: 0.6663\n",
      "Epoch 24/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5495 - accuracy: 0.6663\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5472 - accuracy: 0.6663\n",
      "Epoch 26/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5449 - accuracy: 0.6705\n",
      "Epoch 27/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5426 - accuracy: 0.6756\n",
      "Epoch 28/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5401 - accuracy: 0.6825\n",
      "Epoch 29/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5377 - accuracy: 0.6906\n",
      "Epoch 30/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5351 - accuracy: 0.6972\n",
      "Epoch 31/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5325 - accuracy: 0.7042\n",
      "Epoch 32/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5298 - accuracy: 0.7111\n",
      "Epoch 33/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5271 - accuracy: 0.7181\n",
      "Epoch 34/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5240 - accuracy: 0.7251\n",
      "Epoch 35/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5211 - accuracy: 0.7293\n",
      "Epoch 36/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5178 - accuracy: 0.7289\n",
      "Epoch 37/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5146 - accuracy: 0.7351\n",
      "Epoch 38/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5116 - accuracy: 0.7417\n",
      "Epoch 39/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5078 - accuracy: 0.7436\n",
      "Epoch 40/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5046 - accuracy: 0.7463\n",
      "Epoch 41/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5005 - accuracy: 0.7486\n",
      "Epoch 42/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4975 - accuracy: 0.7537\n",
      "Epoch 43/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4934 - accuracy: 0.7599\n",
      "Epoch 44/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4899 - accuracy: 0.7614\n",
      "Epoch 45/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4862 - accuracy: 0.7649\n",
      "Epoch 46/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4822 - accuracy: 0.7695\n",
      "Epoch 47/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4782 - accuracy: 0.7730\n",
      "Epoch 48/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4745 - accuracy: 0.7776\n",
      "Epoch 49/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4705 - accuracy: 0.7804\n",
      "Epoch 50/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4661 - accuracy: 0.7831\n",
      "Epoch 51/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4620 - accuracy: 0.7854\n",
      "Epoch 52/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4575 - accuracy: 0.7877\n",
      "Epoch 53/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4532 - accuracy: 0.7877\n",
      "Epoch 54/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4482 - accuracy: 0.7927\n",
      "Epoch 55/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4425 - accuracy: 0.7966\n",
      "Epoch 56/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4371 - accuracy: 0.8016\n",
      "Epoch 57/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4320 - accuracy: 0.8047\n",
      "Epoch 58/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4258 - accuracy: 0.8097\n",
      "Epoch 59/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4200 - accuracy: 0.8136\n",
      "Epoch 60/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4130 - accuracy: 0.8155\n",
      "Epoch 61/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4067 - accuracy: 0.8225\n",
      "Epoch 62/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4000 - accuracy: 0.8271\n",
      "Epoch 63/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3927 - accuracy: 0.8310\n",
      "Epoch 64/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3854 - accuracy: 0.8399\n",
      "Epoch 65/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3779 - accuracy: 0.8476\n",
      "Epoch 66/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3696 - accuracy: 0.8480\n",
      "Epoch 67/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3623 - accuracy: 0.8592\n",
      "Epoch 68/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3537 - accuracy: 0.8666\n",
      "Epoch 69/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3462 - accuracy: 0.8674\n",
      "Epoch 70/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3382 - accuracy: 0.8732\n",
      "Epoch 71/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3285 - accuracy: 0.8805\n",
      "Epoch 72/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3202 - accuracy: 0.8848\n",
      "Epoch 73/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3119 - accuracy: 0.8879\n",
      "Epoch 74/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3022 - accuracy: 0.8948\n",
      "Epoch 75/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2931 - accuracy: 0.9006\n",
      "Epoch 76/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2836 - accuracy: 0.9103\n",
      "Epoch 77/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2758 - accuracy: 0.9095\n",
      "Epoch 78/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2656 - accuracy: 0.9188\n",
      "Epoch 79/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2568 - accuracy: 0.9242\n",
      "Epoch 80/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2473 - accuracy: 0.9281\n",
      "Epoch 81/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2381 - accuracy: 0.9335\n",
      "Epoch 82/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2301 - accuracy: 0.9335\n",
      "Epoch 83/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2209 - accuracy: 0.9389\n",
      "Epoch 84/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2134 - accuracy: 0.9389\n",
      "Epoch 85/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2055 - accuracy: 0.9443\n",
      "Epoch 86/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1964 - accuracy: 0.9497\n",
      "Epoch 87/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1895 - accuracy: 0.9524\n",
      "Epoch 88/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1815 - accuracy: 0.9563\n",
      "Epoch 89/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1731 - accuracy: 0.9598\n",
      "Epoch 90/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1661 - accuracy: 0.9656\n",
      "Epoch 91/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1591 - accuracy: 0.9675\n",
      "Epoch 92/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1521 - accuracy: 0.9695\n",
      "Epoch 93/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1447 - accuracy: 0.9749\n",
      "Epoch 94/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1378 - accuracy: 0.9756\n",
      "Epoch 95/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1325 - accuracy: 0.9780\n",
      "Epoch 96/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1272 - accuracy: 0.9787\n",
      "Epoch 97/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1211 - accuracy: 0.9807\n",
      "Epoch 98/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1159 - accuracy: 0.9818\n",
      "Epoch 99/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1119 - accuracy: 0.9872\n",
      "Epoch 100/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1074 - accuracy: 0.9834\n",
      "287/287 [==============================] - 0s 164us/step\n",
      "Epoch 1/100\n",
      "2586/2586 [==============================] - 0s 54us/step - loss: 0.6909 - accuracy: 0.6543\n",
      "Epoch 2/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6858 - accuracy: 0.6671\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6789 - accuracy: 0.6671\n",
      "Epoch 4/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6687 - accuracy: 0.6671\n",
      "Epoch 5/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6550 - accuracy: 0.6671\n",
      "Epoch 6/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6384 - accuracy: 0.6671\n",
      "Epoch 7/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6202 - accuracy: 0.6671\n",
      "Epoch 8/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6056 - accuracy: 0.6671\n",
      "Epoch 9/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5970 - accuracy: 0.6671\n",
      "Epoch 10/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5942 - accuracy: 0.6671\n",
      "Epoch 11/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5930 - accuracy: 0.6671\n",
      "Epoch 12/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5893 - accuracy: 0.6671\n",
      "Epoch 13/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5840 - accuracy: 0.6671\n",
      "Epoch 14/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5793 - accuracy: 0.6671\n",
      "Epoch 15/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5763 - accuracy: 0.6671\n",
      "Epoch 16/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5740 - accuracy: 0.6671\n",
      "Epoch 17/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5719 - accuracy: 0.6671\n",
      "Epoch 18/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5696 - accuracy: 0.6671\n",
      "Epoch 19/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5670 - accuracy: 0.6671\n",
      "Epoch 20/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5644 - accuracy: 0.6671\n",
      "Epoch 21/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5619 - accuracy: 0.6671\n",
      "Epoch 22/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5598 - accuracy: 0.6671\n",
      "Epoch 23/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5577 - accuracy: 0.6671\n",
      "Epoch 24/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5555 - accuracy: 0.6671\n",
      "Epoch 25/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5533 - accuracy: 0.6671\n",
      "Epoch 26/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5513 - accuracy: 0.6671\n",
      "Epoch 27/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5490 - accuracy: 0.6671\n",
      "Epoch 28/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5469 - accuracy: 0.6740\n",
      "Epoch 29/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5447 - accuracy: 0.6787\n",
      "Epoch 30/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5426 - accuracy: 0.6817\n",
      "Epoch 31/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5405 - accuracy: 0.6868\n",
      "Epoch 32/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5383 - accuracy: 0.6937\n",
      "Epoch 33/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5361 - accuracy: 0.7015\n",
      "Epoch 34/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5338 - accuracy: 0.7057\n",
      "Epoch 35/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5317 - accuracy: 0.7096\n",
      "Epoch 36/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5293 - accuracy: 0.7119\n",
      "Epoch 37/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5269 - accuracy: 0.7193\n",
      "Epoch 38/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5245 - accuracy: 0.7231\n",
      "Epoch 39/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5219 - accuracy: 0.7266\n",
      "Epoch 40/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5192 - accuracy: 0.7343\n",
      "Epoch 41/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5165 - accuracy: 0.7351\n",
      "Epoch 42/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5131 - accuracy: 0.7413\n",
      "Epoch 43/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5102 - accuracy: 0.7479\n",
      "Epoch 44/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5068 - accuracy: 0.7467\n",
      "Epoch 45/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5031 - accuracy: 0.7490\n",
      "Epoch 46/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4992 - accuracy: 0.7521\n",
      "Epoch 47/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4960 - accuracy: 0.7575\n",
      "Epoch 48/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4918 - accuracy: 0.7637\n",
      "Epoch 49/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4876 - accuracy: 0.7618\n",
      "Epoch 50/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4835 - accuracy: 0.7657\n",
      "Epoch 51/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4794 - accuracy: 0.7718\n",
      "Epoch 52/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4749 - accuracy: 0.7776\n",
      "Epoch 53/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4706 - accuracy: 0.7823\n",
      "Epoch 54/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4665 - accuracy: 0.7815\n",
      "Epoch 55/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4613 - accuracy: 0.7823\n",
      "Epoch 56/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4575 - accuracy: 0.7892\n",
      "Epoch 57/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4517 - accuracy: 0.7923\n",
      "Epoch 58/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4468 - accuracy: 0.7912\n",
      "Epoch 59/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4405 - accuracy: 0.8009\n",
      "Epoch 60/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4345 - accuracy: 0.8070\n",
      "Epoch 61/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4277 - accuracy: 0.8113\n",
      "Epoch 62/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4210 - accuracy: 0.8163\n",
      "Epoch 63/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4141 - accuracy: 0.8217\n",
      "Epoch 64/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4061 - accuracy: 0.8275\n",
      "Epoch 65/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3980 - accuracy: 0.8349\n",
      "Epoch 66/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3906 - accuracy: 0.8411\n",
      "Epoch 67/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3805 - accuracy: 0.8465\n",
      "Epoch 68/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3713 - accuracy: 0.8558\n",
      "Epoch 69/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3624 - accuracy: 0.8604\n",
      "Epoch 70/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3524 - accuracy: 0.8670\n",
      "Epoch 71/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3425 - accuracy: 0.8751\n",
      "Epoch 72/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3334 - accuracy: 0.8797\n",
      "Epoch 73/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3239 - accuracy: 0.8836\n",
      "Epoch 74/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3138 - accuracy: 0.8940\n",
      "Epoch 75/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3049 - accuracy: 0.8968\n",
      "Epoch 76/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2965 - accuracy: 0.9010\n",
      "Epoch 77/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2887 - accuracy: 0.9022\n",
      "Epoch 78/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2790 - accuracy: 0.9084\n",
      "Epoch 79/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2707 - accuracy: 0.9111\n",
      "Epoch 80/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2616 - accuracy: 0.9153\n",
      "Epoch 81/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2546 - accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2457 - accuracy: 0.9246\n",
      "Epoch 83/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2394 - accuracy: 0.9242\n",
      "Epoch 84/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2301 - accuracy: 0.9319\n",
      "Epoch 85/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2231 - accuracy: 0.9354\n",
      "Epoch 86/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2160 - accuracy: 0.9385\n",
      "Epoch 87/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2081 - accuracy: 0.9432\n",
      "Epoch 88/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2011 - accuracy: 0.9451\n",
      "Epoch 89/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1947 - accuracy: 0.9470\n",
      "Epoch 90/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1878 - accuracy: 0.9501\n",
      "Epoch 91/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1839 - accuracy: 0.9540\n",
      "Epoch 92/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1759 - accuracy: 0.9563\n",
      "Epoch 93/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1686 - accuracy: 0.9609\n",
      "Epoch 94/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1632 - accuracy: 0.9637\n",
      "Epoch 95/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1580 - accuracy: 0.9633\n",
      "Epoch 96/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1530 - accuracy: 0.9652\n",
      "Epoch 97/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1485 - accuracy: 0.9695\n",
      "Epoch 98/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1440 - accuracy: 0.9667\n",
      "Epoch 99/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1389 - accuracy: 0.9695\n",
      "Epoch 100/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1344 - accuracy: 0.9695\n",
      "287/287 [==============================] - 0s 186us/step\n",
      "Epoch 1/100\n",
      "2586/2586 [==============================] - 0s 53us/step - loss: 0.6917 - accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6866 - accuracy: 0.6713\n",
      "Epoch 3/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6800 - accuracy: 0.6713\n",
      "Epoch 4/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6710 - accuracy: 0.6713\n",
      "Epoch 5/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6584 - accuracy: 0.6713\n",
      "Epoch 6/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6425 - accuracy: 0.6713\n",
      "Epoch 7/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6245 - accuracy: 0.6713\n",
      "Epoch 8/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6080 - accuracy: 0.6713\n",
      "Epoch 9/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5974 - accuracy: 0.6713\n",
      "Epoch 10/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5931 - accuracy: 0.6713\n",
      "Epoch 11/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5911 - accuracy: 0.6713\n",
      "Epoch 12/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5882 - accuracy: 0.6713\n",
      "Epoch 13/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5830 - accuracy: 0.6713\n",
      "Epoch 14/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5784 - accuracy: 0.6713\n",
      "Epoch 15/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5752 - accuracy: 0.6713\n",
      "Epoch 16/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5727 - accuracy: 0.6713\n",
      "Epoch 17/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5705 - accuracy: 0.6713\n",
      "Epoch 18/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5679 - accuracy: 0.6713\n",
      "Epoch 19/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5651 - accuracy: 0.6713\n",
      "Epoch 20/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5623 - accuracy: 0.6713\n",
      "Epoch 21/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5598 - accuracy: 0.6713\n",
      "Epoch 22/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5574 - accuracy: 0.6713\n",
      "Epoch 23/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5550 - accuracy: 0.6713\n",
      "Epoch 24/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5527 - accuracy: 0.6713\n",
      "Epoch 25/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5502 - accuracy: 0.6713\n",
      "Epoch 26/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5479 - accuracy: 0.6713\n",
      "Epoch 27/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5455 - accuracy: 0.6713\n",
      "Epoch 28/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5432 - accuracy: 0.6725\n",
      "Epoch 29/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5407 - accuracy: 0.6794\n",
      "Epoch 30/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5383 - accuracy: 0.6875\n",
      "Epoch 31/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5359 - accuracy: 0.6906\n",
      "Epoch 32/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5333 - accuracy: 0.6957\n",
      "Epoch 33/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5309 - accuracy: 0.6988\n",
      "Epoch 34/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5283 - accuracy: 0.7069\n",
      "Epoch 35/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5258 - accuracy: 0.7138\n",
      "Epoch 36/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5229 - accuracy: 0.7189\n",
      "Epoch 37/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5198 - accuracy: 0.7235\n",
      "Epoch 38/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5170 - accuracy: 0.7278\n",
      "Epoch 39/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5137 - accuracy: 0.7312\n",
      "Epoch 40/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5101 - accuracy: 0.7332\n",
      "Epoch 41/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5067 - accuracy: 0.7398\n",
      "Epoch 42/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5029 - accuracy: 0.7463\n",
      "Epoch 43/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4987 - accuracy: 0.7525\n",
      "Epoch 44/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4947 - accuracy: 0.7575\n",
      "Epoch 45/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4902 - accuracy: 0.7633\n",
      "Epoch 46/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4855 - accuracy: 0.7660\n",
      "Epoch 47/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4806 - accuracy: 0.7707\n",
      "Epoch 48/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4761 - accuracy: 0.7757\n",
      "Epoch 49/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4704 - accuracy: 0.7800\n",
      "Epoch 50/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4654 - accuracy: 0.7819\n",
      "Epoch 51/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4605 - accuracy: 0.7865\n",
      "Epoch 52/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4549 - accuracy: 0.7923\n",
      "Epoch 53/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4488 - accuracy: 0.7958\n",
      "Epoch 54/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4432 - accuracy: 0.7970\n",
      "Epoch 55/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4372 - accuracy: 0.8012\n",
      "Epoch 56/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4314 - accuracy: 0.8059\n",
      "Epoch 57/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4249 - accuracy: 0.8117\n",
      "Epoch 58/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4190 - accuracy: 0.8175\n",
      "Epoch 59/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4125 - accuracy: 0.8183\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4063 - accuracy: 0.8198\n",
      "Epoch 61/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4000 - accuracy: 0.8260\n",
      "Epoch 62/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3944 - accuracy: 0.8271\n",
      "Epoch 63/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3881 - accuracy: 0.8314\n",
      "Epoch 64/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3818 - accuracy: 0.8384\n",
      "Epoch 65/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3756 - accuracy: 0.8415\n",
      "Epoch 66/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3688 - accuracy: 0.8469\n",
      "Epoch 67/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3624 - accuracy: 0.8507\n",
      "Epoch 68/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3568 - accuracy: 0.8527\n",
      "Epoch 69/100\n",
      "2586/2586 [==============================] - 0s 6us/step - loss: 0.3503 - accuracy: 0.8550\n",
      "Epoch 70/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3435 - accuracy: 0.8616\n",
      "Epoch 71/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3371 - accuracy: 0.8662\n",
      "Epoch 72/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3301 - accuracy: 0.8670\n",
      "Epoch 73/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3242 - accuracy: 0.8693\n",
      "Epoch 74/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3182 - accuracy: 0.8824\n",
      "Epoch 75/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3104 - accuracy: 0.8832\n",
      "Epoch 76/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.3041 - accuracy: 0.8828\n",
      "Epoch 77/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2976 - accuracy: 0.8879\n",
      "Epoch 78/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2902 - accuracy: 0.8929\n",
      "Epoch 79/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2829 - accuracy: 0.9010\n",
      "Epoch 80/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2755 - accuracy: 0.9091\n",
      "Epoch 81/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2680 - accuracy: 0.9107\n",
      "Epoch 82/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2607 - accuracy: 0.9145\n",
      "Epoch 83/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2533 - accuracy: 0.9169\n",
      "Epoch 84/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2476 - accuracy: 0.9157\n",
      "Epoch 85/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2385 - accuracy: 0.9227\n",
      "Epoch 86/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2315 - accuracy: 0.9288\n",
      "Epoch 87/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2252 - accuracy: 0.9316\n",
      "Epoch 88/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2168 - accuracy: 0.9339\n",
      "Epoch 89/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2096 - accuracy: 0.9377\n",
      "Epoch 90/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2036 - accuracy: 0.9420\n",
      "Epoch 91/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1967 - accuracy: 0.9459\n",
      "Epoch 92/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1884 - accuracy: 0.9493\n",
      "Epoch 93/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1824 - accuracy: 0.9513\n",
      "Epoch 94/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1759 - accuracy: 0.9555\n",
      "Epoch 95/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1684 - accuracy: 0.9594\n",
      "Epoch 96/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1623 - accuracy: 0.9582\n",
      "Epoch 97/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1554 - accuracy: 0.9629\n",
      "Epoch 98/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1501 - accuracy: 0.9660\n",
      "Epoch 99/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1437 - accuracy: 0.9675\n",
      "Epoch 100/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1383 - accuracy: 0.9706\n",
      "287/287 [==============================] - 0s 181us/step\n",
      "Epoch 1/100\n",
      "2586/2586 [==============================] - 0s 54us/step - loss: 0.6919 - accuracy: 0.6036\n",
      "Epoch 2/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6871 - accuracy: 0.6694\n",
      "Epoch 3/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.6810 - accuracy: 0.6694\n",
      "Epoch 4/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6729 - accuracy: 0.6694\n",
      "Epoch 5/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6617 - accuracy: 0.6694\n",
      "Epoch 6/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6470 - accuracy: 0.6694\n",
      "Epoch 7/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6309 - accuracy: 0.6694\n",
      "Epoch 8/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6138 - accuracy: 0.6694\n",
      "Epoch 9/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.6010 - accuracy: 0.6694\n",
      "Epoch 10/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5928 - accuracy: 0.6694\n",
      "Epoch 11/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5893 - accuracy: 0.6694\n",
      "Epoch 12/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5880 - accuracy: 0.6694\n",
      "Epoch 13/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5850 - accuracy: 0.6694\n",
      "Epoch 14/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5805 - accuracy: 0.6694\n",
      "Epoch 15/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5760 - accuracy: 0.6694\n",
      "Epoch 16/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5723 - accuracy: 0.6694\n",
      "Epoch 17/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5696 - accuracy: 0.6694\n",
      "Epoch 18/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5670 - accuracy: 0.6701\n",
      "Epoch 19/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5643 - accuracy: 0.6709\n",
      "Epoch 20/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5614 - accuracy: 0.6748\n",
      "Epoch 21/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5582 - accuracy: 0.6810\n",
      "Epoch 22/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5555 - accuracy: 0.6875\n",
      "Epoch 23/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5525 - accuracy: 0.6899\n",
      "Epoch 24/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5495 - accuracy: 0.6988\n",
      "Epoch 25/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5464 - accuracy: 0.7034\n",
      "Epoch 26/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5432 - accuracy: 0.7080\n",
      "Epoch 27/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5401 - accuracy: 0.7119\n",
      "Epoch 28/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5367 - accuracy: 0.7135\n",
      "Epoch 29/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5334 - accuracy: 0.7212\n",
      "Epoch 30/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5301 - accuracy: 0.7262\n",
      "Epoch 31/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5264 - accuracy: 0.7309\n",
      "Epoch 32/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5232 - accuracy: 0.7301\n",
      "Epoch 33/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5195 - accuracy: 0.7312\n",
      "Epoch 34/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5160 - accuracy: 0.7343\n",
      "Epoch 35/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5126 - accuracy: 0.7405\n",
      "Epoch 36/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5089 - accuracy: 0.7421\n",
      "Epoch 37/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.5054 - accuracy: 0.7456\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.5016 - accuracy: 0.7486\n",
      "Epoch 39/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4980 - accuracy: 0.7552\n",
      "Epoch 40/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4948 - accuracy: 0.7583\n",
      "Epoch 41/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4911 - accuracy: 0.7606\n",
      "Epoch 42/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4872 - accuracy: 0.7626\n",
      "Epoch 43/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4835 - accuracy: 0.7676\n",
      "Epoch 44/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4797 - accuracy: 0.7738\n",
      "Epoch 45/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4757 - accuracy: 0.7773\n",
      "Epoch 46/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4724 - accuracy: 0.7769\n",
      "Epoch 47/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4678 - accuracy: 0.7800\n",
      "Epoch 48/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4637 - accuracy: 0.7892\n",
      "Epoch 49/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4593 - accuracy: 0.7920\n",
      "Epoch 50/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4553 - accuracy: 0.7935\n",
      "Epoch 51/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4506 - accuracy: 0.7943\n",
      "Epoch 52/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4460 - accuracy: 0.8012\n",
      "Epoch 53/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4413 - accuracy: 0.8047\n",
      "Epoch 54/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4369 - accuracy: 0.8059\n",
      "Epoch 55/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4318 - accuracy: 0.8078\n",
      "Epoch 56/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4268 - accuracy: 0.8097\n",
      "Epoch 57/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4217 - accuracy: 0.8144\n",
      "Epoch 58/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4169 - accuracy: 0.8159\n",
      "Epoch 59/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4115 - accuracy: 0.8198\n",
      "Epoch 60/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.4054 - accuracy: 0.8260\n",
      "Epoch 61/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.4004 - accuracy: 0.8248\n",
      "Epoch 62/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3947 - accuracy: 0.8306\n",
      "Epoch 63/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3876 - accuracy: 0.8345\n",
      "Epoch 64/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3823 - accuracy: 0.8399\n",
      "Epoch 65/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3750 - accuracy: 0.8415\n",
      "Epoch 66/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3687 - accuracy: 0.8465\n",
      "Epoch 67/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3619 - accuracy: 0.8507\n",
      "Epoch 68/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3550 - accuracy: 0.8531\n",
      "Epoch 69/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3482 - accuracy: 0.8581\n",
      "Epoch 70/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3415 - accuracy: 0.8662\n",
      "Epoch 71/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3338 - accuracy: 0.8720\n",
      "Epoch 72/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3262 - accuracy: 0.8728\n",
      "Epoch 73/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3190 - accuracy: 0.8797\n",
      "Epoch 74/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3118 - accuracy: 0.8821\n",
      "Epoch 75/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.3041 - accuracy: 0.8840\n",
      "Epoch 76/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2973 - accuracy: 0.8894\n",
      "Epoch 77/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2894 - accuracy: 0.8944\n",
      "Epoch 78/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2802 - accuracy: 0.9029\n",
      "Epoch 79/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2735 - accuracy: 0.9053\n",
      "Epoch 80/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2658 - accuracy: 0.9107\n",
      "Epoch 81/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2575 - accuracy: 0.9142\n",
      "Epoch 82/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2493 - accuracy: 0.9165\n",
      "Epoch 83/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2426 - accuracy: 0.9207\n",
      "Epoch 84/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2342 - accuracy: 0.9269\n",
      "Epoch 85/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2274 - accuracy: 0.9273\n",
      "Epoch 86/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2194 - accuracy: 0.9343\n",
      "Epoch 87/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.2120 - accuracy: 0.9358\n",
      "Epoch 88/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.2046 - accuracy: 0.9412\n",
      "Epoch 89/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1978 - accuracy: 0.9451\n",
      "Epoch 90/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1918 - accuracy: 0.9447\n",
      "Epoch 91/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1847 - accuracy: 0.9501\n",
      "Epoch 92/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1787 - accuracy: 0.9524\n",
      "Epoch 93/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1715 - accuracy: 0.9555\n",
      "Epoch 94/100\n",
      "2586/2586 [==============================] - 0s 4us/step - loss: 0.1655 - accuracy: 0.9586\n",
      "Epoch 95/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1592 - accuracy: 0.9594\n",
      "Epoch 96/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1533 - accuracy: 0.9644\n",
      "Epoch 97/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1479 - accuracy: 0.9664\n",
      "Epoch 98/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1423 - accuracy: 0.9691\n",
      "Epoch 99/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1372 - accuracy: 0.9679\n",
      "Epoch 100/100\n",
      "2586/2586 [==============================] - 0s 5us/step - loss: 0.1335 - accuracy: 0.9706\n",
      "287/287 [==============================] - 0s 197us/step\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator = classifier_sk,\n",
    "                             X = X_train,\n",
    "                             y = y_train,\n",
    "                             cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeXzcVb34/9dksjVJszRJtyRt0zZ5d6O0tLSUsrVRLIhFUZFFARWuGyouKPhTRNzwer3KvfZ6v4pewQUEUaisSstaUiiFQrecNk3SJE2TNHsm+yy/Pz4TOg1ZJs3seT8fjzySfObM53PmZPKe83l/zuccm8fjQSmlVOyKC3cFlFJKBZcGeqWUinEa6JVSKsZpoFdKqRingV4ppWKcBnqllIpxGujVKUTkZRG5YYTHForIpBqPKyK1InKR9+fviMj/+lP2NI5zkYjsP71aKjW6+HBXQPlHRKqAG40xz3p/vwr4FfBBY8wLw5R/GVgNOH02bzDG7ApyPT8B3AIsAjqAN4AfGmNeCeZxR6jLd7Be88Yh22cAtcAZxpgyf/dnjPl+gOoVDwwAhcaYKu++nweWBmL/IxxzKtAAPGuM2Rys46jIpD36KCQi1wNbgPcPF+R9fNYYk+bzFewg/w3gP4DvA7nAXODXwOUjlA92R+N+4AIRmTNk+9XAG+MJ8jHgSqAHuEREpofywCH4O6sx6B8gyojIvwE/At5njHn9NPdxHvALoAgwwBeNMa8OU86OFbivA9qAn4+yzyzgTuBaY8yjPg895v1CRH7gPaYbuAz4oog8CPw78FHv9r8Atxlj+r0B6ffAud7H9hljLvDu61vAzUAaUIf1ofa8b52MMUdF5EXg41htNug64F7vfoqwPoyWAx7gKeBmY0z7MK/xB0C+MeYG7+83AN8DUr3t5Ft2nbe9FmEF2IeBrxljBoAXvcX2e1Nh1wPtwL3GmHne5y8F/gc4E6jxtskT3sf+CLR42/I8YB9wjTGmcmidfVwP/BL4EHAN1t9/sK5zgXuA9YAN+JMx5svexz4DfAXIA44C1wL7GXJG4q1TuTHmThF5j7d9fw18CXhKRL4O/AE4GyvuvIz1NzvmfX428DPgfUAysN0Y82ERKQO+Yox5ylsuCagHzjfG7Bvl9Sof2qOPLp/D6i2XTCDI5wBPYP1TZQP/BTzpDdTDHe9irGCzBqtXOJL1WP/AW8eowoeAPwMZWEH9DqwU03JgpXc/t3vL3gpUYJ0dzAS+430NS4HPAGcZY9KBS4DqEY53H1Zgx+e5S4EHvZtswA+AWcASYP7gcUYjImdgBc5rsILgbG8dBzmBLwM53te0yVtngAu835d6z7QeGbLvROBxrL9TLlag/YuILPQpdo23ntO8r33EtJKIzMf6QPgz8CdObY9473HKgXlAAfCQ97GrgW9jBfd04AqsDxh/5GN9CM8BPo8Va37j/X0u1gfFPT7l/wwkYv0NZvg8dj/WB/Wgy4AqDfLjoz366PJe4Dlgr5/l/0dEBntuh4wxa4APAPuNMQ94t/9RRL4MvB/445DnXwn83BhTCyAidwPnj3CsbKDRGOMao04vG2P+4f25R0SuBW4yxpzwHuMurH/y72EFgwXAHGPMEWAwTeXE6vUtFZGmMXqyjwBbRGSNMeY1rCD3uDGmBcAYcwg45C3bKCI/B745xmsA6wzkUWPMDm+9vwV8YfDBIWmyChH5NXAh1ofDWNZjBb2fGmM8wLMi8hRwFdaHEsBfBz/sReRPnHrGMtR1WKkqIyIPAD8WkTOMMXuBdVgfRt/0+dvt8H6/EbjbGLPb+/sh7/H8iRtO4E5jTL/39x7g74M/i8iPsM6eEJECoATI9jmTGjzr+QPWmU+aMcYBfMK7TY2D9uijy2eBYuBeEbENbhSRe0XE4f36hk/5zxtjMr1fa7zbZmOdgvs6itUrHWo2VtrAt9xImoHpIjLWe6pmyO+zhuzXty53e3/fJiJHRORWAGOMAb4G3IUVnB8QEd/e9Du8weER4Dpv3a7B6uUDICIzReQhETkmIh1YqaKcMV4DDGkb73He6e2KyCIReUJE6r37vcvP/Q7uu9ob5AcN/RvV+/zcjdV7fhfv++Q6rJ48xphqrLTJ9d4iBVg95OE+oAuAI37WeagGnyCPiKR636fV3vbYzsn2KACahkuXGWNqgNeAD4nINKwzzD+fZp0mLQ300aURq+dzPlb+FgBjzI0+F1z/fYx91GGdOvuaAxwbpuxxrH9C33Ij2YHVixtrRMfQ4ZnHh9TnnboYYzqMMV/x5q0/CHxTRC70PvZHY8x6oBCwAz8e5Zj3YfWGB/O/T/k89hOgD2sETjpwA1Y6ZyyntI2IpGGlUQb9P6zc+ULvfu/w2e9YQ1TrgALfD3NG/huN5XysNvqO90OnHlgFXOu9BlMDzPX+PFQN1hnVKYwxTqw2S/HZPPSDduhr/Ia3Hmu87eE7EqoGyBGR9BFew31Y6ZuPAS8aY+pHKKdGoKmbKGOMqRORjcCLIvJzY8xXxrmLx4FfiMjHsHq6VwILgSeHKfsQcIs3bdDLKCkNY0yriHwP+JWIuIF/YQX+i7EunN02wlMfAO4QkTewAuF38KaQROQDwAGsPH074AJcIrIYK7C8gpUS6PE+NpLngC6s4ah/9l4QHTQV6wO03ZtC+Poo+/H1MLDDe9H1DayUim9wm+qtc5e3vp/h5AeYS0Sasa4HVA2z71ew2u5rInIPVrC+FCtfPl7XA08Dn/TZloKV/rsY6+/UDPzI+/fzYF372IF1QfVuEXkF2IP1Pun19rLfwvqwuAPr+sN5WGcKI5mKdebR6r3wesfgA8aYGhF5FivF9kWsv9U6Y8xg+uZvwH9j5f1/eBptMOlpjz4Kef/RNgIfEZHRerLDPfcEVq/7m1j/4F8BLhvMWQ/xK2AbVlDYBfx1jH3/xLvfO737rsG6oPvoKE/7HlbQ2Au8DbzKyd65YJ3iO7DOGO4xxrwMJGGN1GnCSmFkMUoQ9KZA/oB15nD/kIe/i3WhuR3rQvIj+MEY8zbWxdaHsAJ4PaemU76GFWQ7sXr3fxnmuH8WkTYRuWLIvvuwrqVc7n2N/4U1quYQ4yAiKVjXEv7LGFPv81WBlcq53ts7vwxYjPX3qgY+4q3HA1hnPH/Buifib1htDdZomg9hjcb6KGNfhP9PrAvwzVgfZE8NeXzwgushrPH+Xxx8wBjThfUemsPo7yU1ApsuPKKUinTei/RzBoe2qvHR1I1SKqJ5Uz2fxMrRq9OgqRulVMQSkc9hpZMeC8c0GrFCUzdKKRXjtEevlFIxLuJy9G632+NyRfdZht1uI9pfQyBpe5xK2+MkbYtTTaQ9EhLsTVhTZrxLxAV6l8tDW1t3uKsxIZmZKVH/GgJJ2+NU2h4naVucaiLtkZs7dcQ71zV1o5RSMU4DvVJKxTgN9EopFeM00CulVIzz62KsiGzCmiPcjrUKzt3DlLkSa44TD/CWMeYa7/Z/x5rrPA5rAqUvD5l+VSmlVBCN2aP3Tl+6BWsVnyXA1SKyZEiZIqxVgdYbY5ZiLQ6NiJyLtYjCcmAZ1jJiFwbyBSillBqdP6mbNVhrQVZ4FxJ4kHcv9nwTsMUY0wpgjGn0bvdgzf+diDXjYALWzHRKKaVCxJ/UTR6nrgpUC6wdUqYYQER2YKV37jTGPG2MKRWR57AWabABvzTGHBztYHa7jczMlNGKRDy7PS7qX0MgaXucStvjJG2Lk/bXtXO0q50z8zICvm9/Av1wq+0MzbHHY61IfxHW4gAvicgyrKXCFnu3AfxLRC7wWVDgXfSGqdij7XEqbY+TtC0svQMuPn3/btbNz+a7Fxed1j5yc6eO+Jg/qZtaTl1OLh9rqbOhZR4zxgx4F2o2WIH/Q8BOY4zDu6bmU8A546i7UkrFvK376mnu6ueqswvGLnwa/An0u4AiESkUkUSstTeHribzKLABQERysFI5FVjTi14oIvEikoB1IXbU1I1SSk0m/U43971Ww8r8DNYWThv7CadhzEDvXWrsZuAZrCD9kDFmv4jcJSKDC0E/AzSLyAGs9TlvNcY0Yy09dwRrmbi3sIZd/iMIr0MppaLSP/bX0+jo58Zz5gTtGBE3H/3AgMsT7Tk7zTueStvjVNoeJ032thhwubnit7uYPjWJe686k6ys1IlMarYbWD3cY3pnrFJKhckT+xuo7+zjxnVzsNmGG/cSGBrolVIqDJwuN//3Wg1LZ07lnLlZQT2WBnqllAqDpw42Utfey6fPCW5vHjTQK6VUyDndHv7v1WpkehrnzQ/OSBtfGuiVUirE/lnWSE1bLzeGoDcPGuiVUiqkXG4Pv9tZTVFuKhcszA7JMTXQK6VUCG07dIKjrT18+pw5xIWgNw8a6JVSKmTcHg+/3VlNYXYKG4pyQnZcDfRKKRUizx9uoqK5mxtD2JsHDfRKKRUSbo+He3dWMzdrCiXFuSE9tgZ6pZQKgZeONHP4RBefOmcO9rjQ9eZBA71SSgWdx+Ph3tJqCjKTuXjR9JAfXwO9UkoF2Y7KFsoaHdywdg7xIe7NgwZ6pZQKqsHe/Oz0JC5dHPrePGigV0qpoNp5tJX99Z1Wb94enpDrz5qxiMgm4B6shb/vNcbcPUyZK4E7sdaTfcsYc42IbAB+7lNsEXCVMebRiVZcKaUincfj4TevVDNjahKXLZ0RtnqMGehFxA5sAd6LtTbsLhHZaow54FOmCLgdWG+MaRWR6QDGmOeAFd4y04By4J8BfxVKKRWBdlW3sfd4B98sWUhCmHrz4F/qZg1QboypMMb0Aw8Clw8pcxOwxRjTCmCMaRxmPx8BnjLGTN7lZJRSk8q9O6uZnpbI5mUzw1oPfwJ9HlDj83utd5uvYqBYRHaIyE5vqmeoq4AHTq+aSikVXXbXtPFmbTvXnV1AYnx4L4f6k6MfbizQ0IVm44Ei4CIgH3hJRJYZY9oARGQWcAbWIuKjstttZGam+FGtyGW3x0X9awgkbY9TaXucFMttcd/f95GblsT1588nOcHu13OC1R7+BPpaoMDn93ygbpgyO40xA0CliBiswL/L+/iVwN+9j4/K5fJE/WLBk33B46EioT0e3lNHRnJ8WG5WGSoS2iNSxGpbvHWsndKKFr5y0Xx6u/ro9fN5E2mP3NypIz7mz/nELqBIRApFJBErBbN1SJlHgQ0AIpKDlcqp8Hn8ajRto8LE4/Hw/3ZU8V8vVuLxDD0ZVSrw7t1ZzbSUBK5YPivcVQH8CPTGGCdwM1ba5SDwkDFmv4jcJSKbvcWeAZpF5ADwHHCrMaYZQETmYZ0RvBCE+is1pobOPtp7nTR09nGgvjPc1VExbt/xDnZWtfLx1fl+p2yCza9x9MaYJ4Enh2y7w+dnD/BV79fQ51bx7ou3SoVMWYPjnZ+3HWpi6az0MNZGxbrf7qwmIzmeD585O9xVeYfeGati3sFGB3YbnJWfwbbDTZq+UUFzsKGTlytauHZ1PimJkdGbBw30ahIwDQ7mZadw6ZLp1LX3YhodYz9JqdPw29JqpibF89EVkdObBw30KsZ5PB4ONnSyaMZULlyQg91mpW+UCjTT6OCFI81cvSqPtCS/suIho4FexbSmrn5augdYND2NzJQEVhVksl3TNyoIfrezmtREO1etjLxLkhroVUwbvBC7eEYaACXFOVS39nCkKfbGbqvwKW/qYvvhJq46K4+pyZHVmwcN9CrGlTU4sAFFuVagv3BhDnE22HboRHgrpmLK73ZWk5Jg5+qzIq83DxroVYwra3Qwd9qUd0ZAZKcmstI7+kapQKhs7uZZc4IrV84mY0pCuKszLA30KqaVeS/E+tpYlEtlczcVzV1hqpWKJb97tZrkhDiuXZUf7qqMSAO9ilkt3f00OvpZND3tlO0birKxAdt19I2aoKMt3fyzrJGPnDmbzJTI7M2DBnoVwwYvxC6acWqgz01L4sy8dLZr+kZN0P+9VkOCPY5rV0dubx400KsYNnhjlAzp0QNsLM7l8Ikujrbo6Bt1emrbenj6QANXLJ9FdmpiuKszKg30KmYdbHBQkJk87M0rGxZmA2ivXp22379Wgz3OxifOjuzePGigVzHMNHQi04efo3tmejJnzJqqeXp1Wo539PL4/gY+eMYsctOSwl2dMWmgVzGprWeAuo6+d26UGs7G4lzKGh3UtvWEsGYqFtz3Wg1xNrhuTcHYhSOABnoVk97Jz48W6ItyAHhO0zdqHOo7enlsbz2bl81kxtTI782DBnoVo8zgiJthLsQOmp2RzOIZaTrJmRqXP+yqxQNcHyW9efBz4RER2QTcA9iBe40xdw9T5krgTqyFw98yxlzj3T4HuBdrlSkPcKl3MRKlguZgg4PZ6Ulj3qlYUpzLL1+q5HhHL7PSk0NUOxWtTjj6eHTvcS5bOiOq3i9j9uhFxA5sAS4BlgBXi8iSIWWKgNuB9caYpcAtPg/fD/zUGLMYWAM0BqjuSo3INHYiM0ZeLHmQpm/UePxhVy0ut4cboqg3D/6lbtYA5caYCmNMP/AgcPmQMjcBW4wxrQDGmEYA7wdCvDHmX97tDmOMDlxWQeXoc1LT1jvqhdhBBVlTKM5N1fSNGlNTVz9/e/s4lyyZQX7mlHBXZ1z8Sd3kATU+v9cCa4eUKQYQkR1Y6Z07jTFPe7e3icjfgELgWeA2Y4xrpIPZ7TYyM1P8fwURyG6Pi/rXEEihbg9T2QzAqvnZfh330uWz+cW2w/TGxTEzBKfj+v44KZra4n93VjPgcvPl9xYHrc7Bag9/Ar1tmG1DV22IB4qAi4B84CURWebdfj6wEqgG/gLcAPx2pIO5XB7a2qK705+ZmRL1ryGQQt0erx+xAn1+aoJfx11fkMEvgMder+FjIZhmVt8fJ0VLW7R29/OnV6u5eNF0Mu22oNV5Iu2RmztyqtKf1E0t1oXUQflA3TBlHjPGDBhjKgGDFfhrgTe9aR8n8Chw1jjqrtS4lTU6mJ6WyLQU/25Ln5edwvzsFJ26WI3oT7uP0ed086m1c8JdldPiT6DfBRSJSKGIJAJXAVuHlHkU2AAgIjlYKZsK73OzRCTXW24jcCAQFVdqJMNNTTyWkuIc9tS209TVH6RaqWjV1jPAw2/W8R7JpTA7OtJMQ40Z6L098ZuBZ4CDwEPGmP0icpeIbPYWewZoFpEDwHPArcaYZm8u/uvANhHZi5UG+k0wXohSAN39Lo629Iw6fn44G4tz8QAvlGuvXp3qgTeO0T3g4lPnRGdvHvwcR2+MeRJ4csi2O3x+9gBf9X4Nfe6/gOUTq6ZS/jnU6MDDu6cmHsuC7BTmZk1h26EmPnzm7OBUTkWdzl4nf3njGBuLcliYkxru6pw2vTNWxZSyxuHnoB+LzWajpDiHN2raaO3W9I2yPPjmMbr6o7s3DxroVYwpa3SQnZp4WjMKbizOxeWBF8qbg1AzFW0cfU4e2H2MCxdkD7umQTTRQK9iSllD57jz84OKc1PJz0zW0TcKgIf31NHZ5+TT66K7Nw8a6FUM6R1wUdncPeqMlaOx2WxsLMplV3Ub7T0DAa6diiZd/U7+9Hot582fxuJxjuCKRBroVcwob+rC7YHFEzjNLinOweX28OIRTd9MZo/sOU57r5NPR3lufpAGehUzDo6wGPh4LJ6Rxqz0JF1icBLrGXDxx9drOWduFstmpYe7OgGhgV7FDNPgICM5fkKLQQymb3ZWteLocwawdipa/O2t47T2DHBjDOTmB2mgVzHjYEMni2dMxWYbbnom/5UU5+DU9M2k1Dvg4v5dNayek8mZeRnhrk7AaKBXMaHf6ebIBC7E+lo6ayrT0xJ14fBJ6NG99bR0D3BjjOTmB2mgVzHhSHMXLrfntIdW+oqz2dhYnEtpVQtd/Zq+mSz6nG7u31XDyvwMVhVkhrs6AaWBXsWEQFyI9VVSlEO/y8OOipaA7E9Fvq376jnh6I+53jxooFcxwjQ4mJoUT15GYBYOWZ6XTk5qoq48NUn0O938/tVqls9O5+w5sdWbBw30KkaUNTqQGWkTvhA7KM5mY0NRDjsqW+gZGHFBNBUjHj/QQKOjnxvXzQnYeyiSaKBXUc/pclN+whGQ/LyvjUU59DndvFKp6ZtY5nS5ue/VapbOnMo5c7PCXZ2g0ECvol5Fczf9rsBciPW1Ij+DrCkJmr6JcU+XNVLX0RezvXnQQK9iwOlOTTyW+DgbFxVl83JFM72avolZz5om8jOTWV84LdxVCRq/Fh4RkU3APYAduNcYc/cwZa4E7sRaOPwtY8w13u0uYK+3WLUxZvPQ5yo1EWUNDlIS7BRkTQn4vkuKcvn72/W8erSVCxfmBHz/Krz6nG5er2njg2fMjNnePPgR6EXEDmwB3ou12PcuEdlqjDngU6YIuB1Yb4xpFZHpPrvoMcasCHC9lXpHWYMDmZ5KXBD+UVcVZJCRHM+2Q00a6GPQntp2+pxu1s2L3d48+Je6WQOUG2MqjDH9wIPA5UPK3ARsMca0AhhjGgNbTaWG53R7OHTCMe7FwP0Vb4/jwoXZvHikmX6nOyjHUOHzSlULiXYbZxXEznQHw/EndZMH1Pj8XgusHVKmGEBEdmCld+40xjztfSxZRF4HnMDdxphHRzuY3W4jMzM6V1ofZLfHRf1rCKRgtsfhhk76nG7OKpwWtGNsXpnP1n0N7G/uZsMpJ6unR98fJ4W7LV6rbufsedOYlRsZc84Hqz38CfTDnQ97htlPEXARkA+8JCLLjDFtwBxjTJ2IzAe2i8heY8yRkQ7mcnloa+v2r/YRKjMzJepfQyAFsz12HbFGxBSkJQbtGEuyp5CWZGfrm8dYGYALvvr+OCmcbVHf0Uv5CQeXLZkeMX+PibRH7igfVv6kbmqBAp/f84G6Yco8ZowZMMZUAgYr8GOMqfN+rwCeB1b6W3GlxnKwwUFSfBzzpgWvV5hgj+PCBdm8UN7MgEvTN7GitKoVgHWFsTl23pc/gX4XUCQihSKSCFwFbB1S5lFgA4CI5GClcipEJEtEkny2rwcOoFSAmIZOinPTsMcFd8TExuJcOvucvF7TFtTjqNAprWplxtQkCoPYSYgUYwZ6Y4wTuBl4BjgIPGSM2S8id4nI4FDJZ4BmETkAPAfcaoxpBhYDr4vIW97td/uO1lFqItweD6axK+Dj54ezdm4WqYl2vXkqRjhdbl472sq6eVkxPaxykF/j6I0xTwJPDtl2h8/PHuCr3i/fMq8AZ0y8mkq9W3VrD90DrpAE+qT4OM6bP43nDzdx23uKiA/yGYQKrr3HO+nqd7Euhm+S8qV3xqqoZQanJg7w1AcjKSnOpb3XyRuavol6pVUt2G2wJgZnqhyOBnoVtcoaHSTabczPDk2Odd28LKYkxOnC4TGgtLKV5bPTSUvyK6kR9TTQq6hV1tDJwtw04u2heRsnJ9hZX5jNc4ebcLmHjjBW0aK5q5+yRsekSduABnoVpTweD2WNgZ+aeCwlxTm0dA+w51h7SI+rAufVo9awynPmxf6wykEa6FVUOtbei6MvNBdifZ1bOI2k+DhdODyKlVa1kjUlAQlxJyGcNNCrqFQW4DVi/ZWSaOfcwmlsP9yE26Ppm2jj9njYWdXKOfOygjIJXqTSQK+iUlmjg/g4GwuyU0N+7JKiHJq6+tlb1xHyYwdC74CLh948Rle/M9xVCbmyBgdtPQOT4m5YXxroVVQqa+hkQU4qifGhfwuvnz+NRLstKm+e8ng83P3sYX66/Qh/3XM83NUJudKqFmwQs0sGjkQDvYo6Ho+HsobQX4gdlJYUz9q5WWw/3IQnytI3f33rOE8caPR+UJ0Id3VCrrSylUUz0shKSQx3VUJKA72KOg2dfbT3OpEQ5+d9lRTn0tDZx4H6zrDVYbzeOtbOfz53hPWF0/i3c+dxsMFBXXtvuKsVMh29A+w93jGphlUO0kCvos5B74XYxWEM9OcvmEZ8XPSkb5q6+rntHweZMTWJuy4VSoqt1bIm081fu6rbcHvg3Ek0rHKQBnoVdcoaHdhtsDAn9BdiB6UnJ7BmbibboiB943S5+dY/DtDZ5+Snly8hPTmB/MwpLJqexvZJlL4prWwlLcnO0lnp4a5KyGmgV1HHNDgozE4lOcEe1nqUFOVS196LaXSEtR5juefFSt481sG3Ly6mKPfkWdDG4hz2Hu+kviP20zcej4fSqhbWzs2alBPSaaBXUcXj8XCwoTOs+flBFyzMxm4jotM3Tx9s5ME3jvGxlbPZtPjUZRA3Flnpm+fKm8NRtZA60txNo6OfdZMwbQMa6FWUaerqp6V7IGwjbnxlTklg9ZxMth06EZHpm8MnHPzgn4dYmZfOLRfOf9fjc6elUJSbOinSN6WVLQCcM2/yXYgFPwO9iGwSESMi5SJy2whlrhSRAyKyX0T+POSxdBE5JiK/DESl1eQVCRdifW0szqWmrZfypq5wV+UUnb1OvrH1AFOT4vnRB5aMOPHbxqIc3jrWwQlHX4hrGFqlVa0syElhxtSkcFclLMYM9CJiB7YAlwBLgKtFZMmQMkXA7cB6Y8xS4JYhu/k+8EJAaqwmNdPgwAan5JrD6aKF2cRFWPrG7fFwx1Nl1Hf0cfcHFpOTOvKY8ZLiXDzAc4djN33T3e9iz7F21k3S3jz416NfA5QbYyqMMf3Ag8DlQ8rcBGwxxrQCGGMaBx8QkVXADOCfgamymszKGh3MnTaFlMTwXogdNC0lkbPyMyJqkrPfllbzckULX7loAWfmZYxatjA7hcLsFLYfjt30ze6aNgZcnkmbnwf/An0eUOPze613m69ioFhEdojIThHZBCAiccDPgFsDUVmlyho6WTRjarircYqNxblUtnRT0Rz+9M3LFc38pvQo718ynY+umOXXc0qKcniztp3mrv4g1y48SqtaSY6PY8UYH3qxzJ/lVYYbizT0ylM8UARcBOQDL4nIMuDjwJPGmBoR8atCdruNzMzoXpXdbo+L+tcQSIFqjyZHH42OflbOzYqo9r18VT4/3V7Ojup2zlqQO2b5YL0/jrZ0892nDItmTuXuj5zp9/DTD64q4N6d1bxW18HVZ88JeL1GE4r/lVer21i3IJvpOZGR7htNsNrDn0BfCxT4/J4P1A1TZsuIsoIAACAASURBVKcxZgCoFBGDFfjXAeeLyOeBNCBRRBzGmGEv6AK4XB7a2rrH8xoiTmZmStS/hkAKVHu85h05MTc9KaLaNxFYMTudJ98+zidWzh6zfDDeHz0DLj775z0A/PiyRfR29eHv6PjpSXHMyZrC43vquMQ75DJUgv2/UtPaQ3VLNx9bMTui3jMjmUh75OaOfKbrT+pmF1AkIoUikghcBWwdUuZRYAOAiORgpXIqjDHXGmPmGGPmAV8H7h8tyCs1msE56CNxwYiNxbmUN3VR1RL6YOLxePjhPw9xpKmLH7x/EXkZU8b1fJvNxsaiHHbXtNHWPRCkWoZHaZXVOTh3kk1LPNSYgd4Y4wRuBp4BDgIPGWP2i8hdIrLZW+wZoFlEDgDPAbcaY2L3Mr4Ki7JGBwWZyRG5oPOGwZuPwjB3zF/erOOZshN8dv280x5ZUlKcg8sDLxyJnIvKgVBa1UpBZjL5meP78Is1fv3HGGOeBJ4csu0On589wFe9XyPt4/fA70+nkkoBmIbOiJ2nZMbUJM6Ylc62Q018cm3o8txv1rbzixcquGBBNjesLRj7CSOQ6WnMzkhm26EmLj/Dv4u4ka7P6eb16jY2L5sZ7qqEnd4Zq6JCW88AdR19EXFH7EhKinMwjQ5q23pCcrwTjj5u+8cB8jKS+d4lMqGl8Ww2GyVFOeyqbqOjNzbSN3uOtdPrdE+61aSGo4FeRYXBicMiYY6bkWwcnPo3BGPqB1xuvrn1ID0DLv5985KApLNKinNwuj28dKQlADUMv9LKVhLsNlYVZIa7KmGngV5FhXcWA4/gHv2s9GSWzJzKthDk6X/+fAV7j3fwnfcJCwI0XfOSmVOZMTUpZlae2nm0hRV5GUwJ8yynkUADvYoKZQ0OZqcnkTElIdxVGVVJUQ4H6js5HsSpf5/Y38DDe+q4dlU+75Wxx+37y2azUVKcw86jrTj6onvh8IbOPo40dU/qu2F9aaBXUcE0diIRdkfscAbTN8EafWMaHPz42cOsKsjg5gsKA77/jUU5DLg8vFwR3embnd5hlZNx2cDhaKBXEc/R56SmrTdiZqwcTX7mFIpzU4MyyVl7zwDf2LqfjOR4fnTZ4qAsoHHG7HRy0xKjPn1TWtXK9LREFmRHzh3U4aSBXkW8dy7ERnB+3ldJcS5v13XQ2Bm4qX9dbg/ffrKME139/GTzEqaljDwj5UTEeW+eKq1qpbvfFZRjBJvT7eHVo62smzcN2wRGIsUSDfQq4r1zITYKevQQnPTNr0uPsrOqla9vXMiyIN9LsLE4hz6nmx2V0Zm+2X+8A0efS4dV+tBAryLewYZOpqclBq0XG2jzpqWwICclYKNvXihv4nc7q9m8bAYfOiP4N/+cOTuDaSkJUbvy1CtVrdhtsGaOBvpBGuhVxDONjoibmngsJUW57Kltp2mCU/8Ozki5eEYa3ygpCkkqwh5nY0NRDi9XtNA7EH3pm9LKFpbNSmdqcuRNlREuGuhVROvud3G0pSdq0jaDNhbn4AGen0Cvvrvfxa1bDxAfZ+Mnm5eQFB+6f9eS4hx6nW5eqWoN2TEDoaW7n4MNDk3bDKGBXkW0Q40OPET2jVLDmZ+dwrxpU047fePxePj+M4c42tLNDy9bzKz05ADXcHQr8zPJnBJ96ZtXj1ofTJN52cDhaKBXEa2sMbouxA6y2WxsLM7ljZo2WrvHn7750+5jPHvoBJ8/r5C1c0PfO42Ps3HRwmxeOtJCn9Md8uOfrtLKVjKnJETd+yXYNNCriFbW0El2aiK5aUnhrsq4lRTl4PbA8+Xjm7H79eo2fvliBRuLcrju7Pwg1W5sJcU5dA+42Bkl6Ru3x8POqlbOmZc1oQneYpEGehXRyhodUZe2GVSUm0pBZvK4Jjmr7+jlW48fpCBrCndsKg7rOPDVBZmkJ8dHzcLhptFBa8+ATnswDA30KmL1DriobO6O6BkrRzOYvtlV3Upbz9hT//Y73dz2j4P0u9z8dPNSUhPDO2ok3h7HhQuyefFIM/1RkL4prbTOPM7RQP8ufgV6EdkkIkZEykVk2KUAReRKETkgIvtF5M/ebXNFZLeI7PFu/2wgK69i2+ETXbg9sDhKe/RwcuWmF4+Mnb752XNH2F/fyR2bhHkRcut+SXEujj4Xu6rbwl2VMZVWtbB4RlrU3G8RSmMGehGxA1uAS4AlwNUismRImSLgdmC9MWYpcIv3oePAucaYFcBa4DYRGXv1ZKWI3guxvhZNT2N2etKY6Zute+v529vHuX5NARtDvED3aM6ek0lqoj3i577p7HWyt65D0zYj8KdHvwYoN8ZUGGP6gQeBy4eUuQnYYoxpBTDGNHq/9xtjBif8SPLzeEoB1kyNGcnxzJgafRdiBw2mb1492kpn7/BT/x6o7+Qn2w6zZk4mn1s/L7QVHENifBwXeNM3Tlfkpm92Vbfi8uiwypH4kwTMA2p8fq/F6p37KgYQkR2AHbjTGPO0d1sB8ASwEGvR8LrRDma328jMjIzT1tNlt8dF/WsIpNNtj0NNXZyRn0FWVmAW1giXy8/K54+v17K7vpMPrsg7pT1auvq5/fGD5KQl8d/XnMW01MhLO2xemcdTBxspa+3lvIWBPdsI1P/K7rpOpibHc97iGcTbo7c/GazY4U+gH+6yv2eY/RQBFwH5wEsisswY02aMqQGWe1M2j4rIX40xDSMdzOXy0NbW7V/tI1RmZkrUv4ZAOp326He6OdTo4ONz8qO+LeemJTBjahL/2FPHRfOy3mkPp9vDlx7ZS5Ojj3uvXkHcgJO2tshb8GNZTgopCXa2vlnLspzABqFA/K94PB6eN42cXZCJozN4C76EwkTaIzd35GlC/PnoqwV8l5fPB4b2ymuBx4wxA8aYSsBgBf53eHvy+4Hz/TimmuSONHfhcnuiYg76sdi8U//urGqhq/9kIP/Vy1Xsqm7jm+8pYnEEz+WTnGDnvPnTeP5wM0730D5e+FU0d9Po6Nf8/Cj8CfS7gCIRKRSRROAqYOuQMo8CGwBEJAcrlVMhIvkiMsW7PQtYj/UhoNSoDjZE1xz0YykpzqHf5WGHd+Wm7YdOcP+uGq5YPovNy4I/I+VElRTn0NozwJ7a9nBX5V1Kq3RY5VjGDPTGGCdwM/AMcBB4yBizX0TuEpHN3mLPAM0icgB4DisX3wwsBl4VkbeAF4D/MMbsDcYLUbHFNDiYmhRPXkZo53gJljNmp5OTmsi2Q02UNzr43tOHWDZrKl/bsCDcVfPLuYXTSI6Pi8jRN6WVLczPTmFmiOcDiiZ+3ZFhjHkSeHLItjt8fvYAX/V++Zb5F7B84tVUk83Bhk5kRlrMrBAUZ7Om/t26r56qB94kOSGOuz+whMQQzkg5EckJdtbPn8Zz5c18feNC7EFYxvB09Ay4ePNYO1euyAt3VSJadLzL1KTidLkpb+qK2qkPRlLiXbnpaEs3P7pscdQNG91YlENzVz9v13WEuyrveKOmnQGXR/PzY9CZ+VXEqWjuZsDliblAvyIvg/PmT2PTGbNYVZAZ7uqM2/r500jypm9W5meEuzqAdTdsUnwcKyKkPpFKe/Qq4kTbGrH+ssfZ+PmHlvGx1QVjF45AqYnxrJuXxXOHm3B7ImP0TWlVK6sLMkO6KEs00tZREaes0UFKgp2CrCnhrooaYmNxDo2OfvYd7wx3Vaht66G6tUfTNn7QQK8iTlmDA5meqnOKR6Dz52eTYLdFxOibwWGV6wp12oOxaKCPUY4+J8c7ou8uQafbw6ET0bcY+GSRlhTP2rlZbD/UhCfM6ZvSyhbyMpIpyNRhlWPRi7ExorvfxZ5j7eyuaeP1mnbKGjqJs9l44LpVETPlrT+OtnTT53THXH4+lpQU5/ByRQsHGhwsnRmeD+R+p5vXa9p4/5IZMTMEN5g00Eep3gEXbx3r4PWaNnbXtHGgvhOXx1rrc9msqdywpoAH36jjf1+p4u4PLBl7hxHCxMDUxLHuggXZ2ONsbD90ImyB/q26dnoG3Jq28ZMG+ijRO+Bi3/HOdwL7vuOdON0e7HE2lsyYynVrCliVn8nyvHSmJNgBa5THb0qr2V/fGbZ/yPE62OAgKT6OuVnRcxYy2aQnJ7BmTibbDjVx8/mFYelRl1a2Eh9nY3UUDlMNBw30Earf6WZffQe7q9t5vaaNfcc76Hd5iLPBohlTuWZVHqsKMlmRl0FKon3YfVy7Op+H9xxny0uV/M9Ho+MGZdPQSXFuWsTceamGV1Kcww/+eZhDjV1hWeqxtKqVFfkjv/fVqTTQR4gBl5sD9VaP/fWadvbWddDndGPDmtjroyvyWD0ngxV5GaQl+fdnS02M51PnzOE/nzvCq1WtrI3wYWhujwfT2MVlS2eEuypqDBcuyOHHtsNsO3wi5IG+sbOP8qYuvnRBYUiPG8000IeJ0+2hrKGT16vb2F3Tzp5j7fR6F2Auyk3lQ8tnsbogg5X5GaQnJ5z2cT68fBYP7K5ly8uVnD03M6KHLFa39tA94IraxcAnk8yUBM4qsNI3n1s/L6Tpm52Dwyp1NSm/aaAPEZfbg2l0eEfFtLGntoPuARcA87NT2LxsJqvmZHJWfgaZU04/sA+VGB/HZ86dx51PG7YdauK9khuwfQeaGbwjNsamPohVJcU53P1sOUeau1mYE7pVwEqrWshNS2RBgBdBiWUa6IPE7fFwuLGL3bVtvF7dxpvH2nH0WYF93rQpXLJkOqsKMllVkBH0Ves3LZ7OH16v4VcvV7JhYXbELrV2sMFBot3G/CgaDjqZXbQwh588W872QydCFuidbg+vHm1jQ1G2DqscBw30AVbf0ct3nja8cqSZDu9i0AWZybynOJfV3sCekxbaWQvtcTa+cF4hX310P1v31XPFmbNDenx/mcZOFuamRewHkTpVdmoiK/Mz2HaoiX87d15Ijrn/eAedfU5N24yTBvoAaujs47MPvU1b7wAlRTneHntmRExHe978aZw5O53flFZz6ZIZJCdE1mgFj8dDWaODi2V6uKuixqGkOIefbj9CZXM3hSE4EyutaiXOBmvm6rDK8fAr0IvIJuAewA7ca4y5e5gyVwJ3Yi0c/pYx5hoRWQH8CkgHXMAPjTF/CVDdI0pjZx+fe+gt2noG+P0NZzNvanDTMeNls9m4+fxCbvrLWzz4xjFuWDsn3FU6xbH2Xhx9Lr1RKspsKLIC/fbDJ/h09tygH6+0qpVls9InNEBhMhrzHFlE7MAW4BJgCXC1iCwZUqYIuB1Yb4xZCtzifagbuM67bRPwCxGJuY/iJkcfn3v4bZq7BrjnimWsiNCbOFbkW/Oh37erhvaegXBX5xSxOjVxrMtNS+LM2elsO9QU9GO1dvdzsL5TZ6s8Df4kQ9cA5caYCmNMP/AgcPmQMjcBW4wxrQDGmEbv90PGmMPen+uARiByh32chqaufj738NuccPRxzxXLODMvshdA+MJ5hXT1ubjvtZpwV+UUZY0O4uNsLMgO3egNFRgbi3M4fKKL6taeoB7n1aNteNDZKk+HP6mbPMA3KtQCa4eUKQYQkR1Y6Z07jTFP+xYQkTVAInBktIPZ7TYyM6Nj1EWzo48vPrKPhs5+7r1uNWu8F4js9riIfQ2rM1P44IrZPLSnjpsuWsisECy+7U97lDd3UzxjKtNzYr9HH8nvj9PxwVUF/Pz5Ckpr2llemD2u546nLXYf6yArJYF1xdOJi9E7p4P13vAn0A/XokPnJ40HioCLgHzgJRFZZoxpAxCRWcAfgOuNMe7RDuZyeWhr6/ajWuHV2m315GvbernnimUUZya/U+/MzJSIfg03rM7n8b3H+dkzZXz74uKgH2+s9vB4POw71s5FC3Miut0CJdLfH+OVAiybNZUn3q7jY8tnjuu5/raF2+PhxcMnWDMnk46O4J45hNNE3hu5uSPPZ+VP6qYW8F37LB+oG6bMY8aYAWNMJWCwAj8ikg48AXzbGLNzHPWOWG3dA3zhr3upbevlPz+4NOrW/5ydkcyHz5zNP/bVU9Uc/oBT39lHe69T8/NRbGNRDgcbHBxrD04QPtzYRUv3AOdq2ua0+BPodwFFIlIoIonAVcDWIWUeBTYAiEgOViqnwlv+78D9xpiHA1ft8GnvGeALf32boy3d/OzypayZG50Xhj65toDkeDu/2lEV7qrohdgYsLE4B4DtQboo+0pVCwBro/T/LdzGDPTGGCdwM/AMcBB4yBizX0TuEpHN3mLPAM0icgB4DrjVGNMMXAlcANwgInu8XyuC8kpCoKPX6slXtnTzHx9cGvGThI1mWkoiH1+dz/bDTew/3hHWupQ1OrDbCOlt9Cqw8jKmsHhGGtsPByfQl1a1ItPTyE6NrGHL0cKvcfTGmCeBJ4dsu8PnZw/wVe+Xb5k/An+ceDXDr7PXyc1/3UtFcxc/3bw0Ju7Mu2Z1Hg/vqeOX3mmMw3VLeVlDJ4XZqRF3E5can41FOWx5uYr6jl5mpgfuIr+jz8nbdR18YnV+wPY52ei95n5w9Dn54iN7OXyii598YAnr50d/kIeT0xi/XtPOq0dbw1IHj8djLQauaZuot7HYGjkd6F79ruo2XG4P6wqj9ww63DTQj8HR5+RLj+ylrNHB3R9YzPkLxjd8LNJdsXwWs9OT2PJSFe4wLPbc1NVPS/eAzlgZA+ZkTaEoNzXgefrSqhZSE+0sn5Ue0P1OJhroR9HV7+TLf9vHgfpOfnzZYi5cmBPuKgVcYnwcn1k/j7JGB8+aEyE//kHvhdjF2qOPCSXFObxV10FjZ19A9ufxeCitbOXsOZk62d0EaMuNoLvfxS1/28f+4x388LLFbCiKvSA/6H2LprMwJ5X/3VGF0zXqbQ4BZxoc2ICiXA30saCkyErfPF8emF59VUsP9Z19ejfsBGmgH0bPgIuv/H0fb9d1cNeliygpjqlZG97FHmfjC+fPo6atl8f21Yf02GWNDuZOm6Jrf8aIedkpzM9OCVievtQ7rFLnt5kYDfRD9A64+Orf97HnWDt3XbKIixdNjmlz1xdOY0WeNY1xj3flq1Aoa+hk0YyR7+hT0WdjUQ5v1rbT3NU/4X2VVrZSOC2FWQEcxTMZaaD30Tvg4muP7md3TTvf3SS8b/HkCPJwchrj5q5+HnzjWEiO2dzVT6OjXy/ExpiS4lzcHnhhgumb3gEXb9S26WibANBA79XndHPrYwfYVd3GHZuKuXTJjHBXKeTOzMvg/PnTuD9E0xiXNeodsbFoQU4Kc7KmTHjq4t217fS7PJq2CQAN9EC/0803tu5n59FWvn1xMZctHd/ETLHk8+eHbhrjwcXARXv0McVms1FSnMPumjbauk+/w1Ba2UJSfBwr86NrLqlINOkDfb/TzTf/cYBXKlv51nuL2HzG5A3yYE1DcOmS6Ty0p46GAA2RG0lZo4OCzGTSknRFy1hTUpSLywMvHDn9Xn1pVSurCjJIip/0YWrCJnULDrjc3P74QV6uaOG29yzkQ8tnhbtKEeEz6+fh9nj4zStHg3ocvRAbu4qnp5KXkXza6Zvath6qW3tiYqqRSDBpA73T5eZbjx/kxSPN3LpxIR8+c3a4qxQxZqUn85EzZ/OP/cGbxritZ4DjHX16ITZGDaZvXqtuo6N3/OmbnVXWlByanw+MSRnonS43/98TZTxf3szXNyzgypUa5If65NoCpiTY+Z8gTWNsvBdidY6b2LWxOBeX28OLR5rH/dzSqlZmZyQzJ2tKEGo2+Uy6QO90e/jOk2VsP9zEVy6az8fOygt3lSJSVkoi167O57kgTWP8zhz02qOPWUtmpDFzatK40zcDLje7qltZNy8rbDOqxppJFeidbg/ffbKMZw818aULCrlmlU57OpprVuWRNSWBX75UiSfAE56VNTiYnZ5ExpSEgO5XRQ6bzcbG4hxePdqKo8/p9/PeOtZBz4Bb8/MB5FegF5FNImJEpFxEbhuhzJUickBE9ovIn322Py0ibSLyeKAqfTpcbg/fe9rwT3OCm88v5BNnF4z9pEkuNTGeT3unMd4Z4GmMTWMnohdiY15JcS4DLg8vVfifvimtaiE+zsbqORlBrNnkMmagFxE7sAW4BFgCXC0iS4aUKQJuB9YbY5YCt/g8/FPgEwGr8WlwuT18/xnD0wcb+fx587h+jQZ5f11xZuCnMXb0Oalp69UZKyeBZbOmMj0tcVxTF5dWtbIiL53URB12Gyj+9OjXAOXGmApjTD/wIHD5kDI3AVuMMa0AxpjGwQeMMduAzgDVd9zcHg8/+OchnjjQyL+dO5dPrp0TrqpEpQS7NY2xCeA0xu9ciNX8fMyLs9nYUJTDK5UtdPWPnb454ejj8IkuTdsEmD+BPg/wvU2y1rvNVzFQLCI7RGSniGwKVAUnwu3x8KN/Hebx/Q3ceM4cblo3N9xVikqbFk+nKDeVXwVoGuODuhj4pFJSnEu/y8OOipYxy74zrFLntwkof86NhrvsPfQcPh4oAi4C8oGXRGSZMaZtvBWy221kZqaM92nv4nZ7+O7jB3hsbz2fu3A+XykpCtkVfLs9LiCvIZLc+j7h3/74Bs8caeHaNeM7KxraHhWtPcxMT2b+7Ml5a3ssvj9Gc0H6FHLTynipqpUrz5l3ymND22L3sQ6mT01i9cLcSTniJljvDX8CfS3gm9TOB+qGKbPTGDMAVIqIwQr8u8ZbIZfLQ1vbxG7S8Xg8/GRbOY+8dZzr1xTwyVV5tLf3TGif45GZmTLh1xBpVkxPZWVeOv+9vZyNhVlMGcdC3kPbY29tG8W5qTHXRv6KxffHWC5cMI3H9zdw/ETnKe8d37ZwuT28VN7EBQuyQ/r/Gkkm8t7IzR15cIM/qZtdQJGIFIpIInAVsHVImUeBDQAikoOVyqk4rdpOkMfj4WfPHeGRt47z8dX5fOG8eZOyZxBoNpuNLwRgGuOufidHW3o0bTPJlBTn0ut0U1o5cvrmQH0nHb1OvRs2CMYM9MYYJ3Az8AxwEHjIGLNfRO4Skc3eYs8AzSJyAHgOuNUY0wwgIi8BDwMlIlIrIu8LxgsBK8j//PkK/vJmHdesyuNLFxRqkA+gM/MyuGBBNve9VkPbaU5jfLixCw96o9RksyI/g6wpCaOuPFVa1UKcDdbM1UAfaH6NXzLGPAk8OWTbHT4/e4Cver+GPvf8CdbRb798qZIH3jjGx1bO5pYL52uQD4LPnzePq+/bzX2v1fDlC+eP+/k6B/3kFB9n46KibJ45eII+p3vYGSlLq1pZOnMqmXoTXcDFzJ2xbo+HJw408rGVs/nahgUa5INkQU4qly6dwUNvHqO+o3fczy9r6CQ7NZHctKQg1E5FspKiXLoHXO+MrPHV1jPA/uOdOqwySGIm0MfZbDx+0xq+vnGhBvkg+8y5c/EA95ZWj/u5ZY0OTdtMUqsKMkhPjmf74Xffj/Ha0VY86LDKYImZQA8Qb4+plxOxfKcxrhzHNMa9Ay4qm7t1xspJKt4ex4ULsnnxSDP9zlPvx3ilqpWM5HgW67QYQaGRUZ2WT62dY01j/HKl3885fKILtwcWa49+0iopzsXR52JX9clbbNweD6WVLaydm4U9Ts/Gg0EDvTotmSkJfHx1Ps+XN7PPz2mM9UKsOntOJmlJdrYdOpm+OXyii5buAU3bBJEGenXarlmVz7QU/6cxLmvoJHNKAjOm6oXYySoxPo4LFmTzwpHmd6bTGBxbf44OqwwaDfTqtKUk2vn0OXPY7ec0xmUN1oVYvVg+uW0syqWj18nrNVb6prSqleLcVHJ0JFbQaKBXE/Kh5bOYnZHML1+sHHUa436nmyN6IVYB58zLIiXBzrZDTXT2OnmrroN1hTqsMpg00KsJSbDH8dn1czl0oot/lY08jXF5Uxcut0fnoFckxcdx/oJpPF/ezMvlTbjcHp32IMg00KsJe9+ik9MYD4wwjXGZzkGvfGwszqWtZ4D/2l5OaqKd5bPTw12lmKaBXk1YnM3GF84r5Fh7L4/urR+2jGlwMDUpnryM5BDXTkWic+dlkRwfR/kJB2fPySRB74EJKm1dFRDnFmaxMj+De0uP0jPgetfjBxs6kRl6IVZZkhPsnDffystr2ib4NNCrgLDZbNx8fiEt3QM8sPvUaYwHXG7Km7p06gN1ig8sm0lqop3187PDXZWYp4FeBczy2elcuCCb+3edOo1xeaODAZdHA706xbmF03jz2+/R+ypCQAO9CqjPnTePngEXv3/15DLD++qsO2f1jlg1lKbyQkMDvQqoBTmpXLpkBg/vOTmN8YHjHaQm2inImhLm2ik1OfkV6EVkk4gYESkXkdtGKHOliBwQkf0i8mef7deLyGHv1/WBqriKXIPTGP+m9CgA++raKZ6eRpz23pQKizEDvYjYgS3AJcAS4GoRWTKkTBFwO7DeGLMUuMW7fRrwXWAtsAb4rojoJfYYNzM9mY+umM3j+xsoP9FFWX2n5ueVCiN/evRrgHJjTIUxph94ELh8SJmbgC3GmFYAY0yjd/v7gH8ZY1q8j/0L2BSYqqtI9sk11jTG33myjN4Bt+bnlQojf9aMzQNqfH6vxeqh+yoGEJEdgB240xjz9AjPzRvtYHa7jczMFD+qFbns9riofw0TlZkJN50/n19sOwzA2QtzJ32bDNL3x0naFqcKVnv4E+iHS6wOnb0qHigCLgLygZdEZJmfzz2Fy+Whrc3/VYsiUWZmStS/hkD40JLp3F9aRfeAi2nxNm0TL31/nKRtcaqJtEdu7sirc/kT6GuBAp/f84G6YcrsNMYMAJUiYrACfy1W8Pd97vN+HFPFgJREO9/dJLT2u3XlIKXCyJ9AvwsoEpFC4BhwFXDNkDKPAlcDvxeRHKxUTgVwBPiRzwXYi7Eu2qpJ4tzCadprUyrMxrwYa4xxAjcDzwAHgYeMMftF5C4R2ewt9gzQLCIHgOeAW40xzcaYFuD7WB8Wu4C7vNuUUkqFiM2fJeBCaWDAXtImygAABgVJREFU5Yn23p/2YE+l7XEqbY+TtC1ONcEc/W5g9XCP6Z2xSikV4zTQK6VUjNNAr5RSMU4DvVJKxTgN9EopFeM00CulVIyLuOGVwAngaLgroZRSUWYukDvcA5EY6JVSSgWQpm6UUirGaaBXSqkYp4FeKaVinAZ6pZSKcRrolVIqxmmgV0qpGOfPwiPKTyJSANwPzATcwK+NMfeEt1bhJSJ24HXgmDHmsnDXJ5xEJBO4F1iGtaTmp4wxpeGtVfiIyFeAG7HaYi/wSWNMb3hrFToi8jvgMqDRGLPMu20a8BdgHlAFXGmMaZ3osbRHH1hO4GvGmMXAOcAXRGRJmOsUbl/GWrBGwT3A08aYRcCZTOJ2EZE84EvAam+Qs2OtXjeZ/B7YNGTbbcA2Y0wRsM37+4RpoA8gY8xxY8wb3p87sf6R88Jbq/ARkXzg/Vi92ElNRNKBC4DfAhhj+o0xbeGtVdjFA1NEJB5I4d1rUcc0Y8yLwNAV9y4H7vP+fB/wwUAcSwN9kIjIPGAl8GqYqxJOvwC+gZXGmuzmY03v8X8i8qaI3CsiqeGuVLgYY44B/wFUA8eBdmPMP8Nbq4gwwxhzHKyOIzA9EDvVQB8EIpIGPALcYozpCHd9wkFEBnOPu8NdlwgRD5wF/MoYsxLoIkCn5dFIRLKweq+FwGwgVUQ+Ht5axS4N9AEmIglYQf5Pxpi/hbs+YbQe2CwiVcCDwEYR+WNYaxRetUCtMWbwDO+vWIF/snoPUGmMOWGMGQD+Bpwb5jpFggYRmQXg/d4YiJ1qoA8gEbFh5WAPGmP+M9z1CSdjzO3GmHxjzDysi2zbjTGTtsdmjKkHakREvJtKgANhrFK4VQPniEiK9/+mhEl8cdrHVuB678/XA48FYqc6vDKw1gOfAPaKyB7vtm8ZY54MY51U5Pgi8CcRSQQqgE+GuT5hY4x5VUT+CryBNVrtTeDX4a1VaInIA8BFQI6I1PL/t3c/IVZWcRjHv0OLlP5gREQIQYQ+UCQjaiHY1GwE2zQWCdUmjFoYhIiC0GJwpdAmEo1CoiIKQhKClGgxUEohpP2FnkXkCO2MilBxIbQ4Z/DlcmfuTI7CPT4fuHDf9557zsuF+9z3Pdz3d2AS2Ad8IulFyo/hM4sxVsoUR0Q0LlM3ERGNS9BHRDQuQR8R0bgEfURE4xL0ERGNy98rY6hIukypdDhjwvaZWdo+DuzsVzWz3si11va5fvspf/l7zvbBRTjsmb63UyqaXqjbR+sYN3rNm7jGEvQxbC7aHr0O4ywDtgHzDvp648+I7dlq+2wHPgQuANh+4moPMmI+EvQx9CQtAd7iypn4DttTPW3uBD4G7gJOAiMDut0H3F9vfPvS9i5Ju4AtwM3AEduTtXjdMWAKWA9MSNoNrAOWAodru1cpNV2mJJ2zPd69qpC0A9haxz5k+41O38cp5QH+AJ60ffF/fVBxw8ocfQybpZK+r48jdd8rALYfAp4F3q/h3zUJHK8FxT4D7h0wzm7gN9ujNeQ3AiuAh4FRYI2ksdpWwAe2V9ueBl6zvRZYBTwmaZXtNylleMdtj3cHkrSGcpfsI5R1DF6StLq+vAI4YPtB4G/g6fl9TBFX5Iw+hk2/qZsNwH4A279KmgZW9rQZA56qbT6XtNBVezbWx+m6fSslhM8C07a/7bTdIullyvfrHuAB4Mc5+t5AuUI4DyDpU+BRyg/S77Znyml8R1l5KGJBEvTRgkHTMDOupt7HCLDX9tvdnXV65Xxn+z5gJ7DO9l+S3gN6ry769T2bS53nlynTQRELkqmbaMFXwPMAklZSpmU8R5tNwB0D+vwXuK2z/QWwta41gKTlkvotCnE7Jfj/kXQ3sGmOPrvHNlErOd4CbAa+HnB8EfOWoI8WHARukvQTZWHlF2xf6mmzBxiTdIoyBXN2rg5t/wmckPSzpNfr6kcfAd/UcQ7TJ7Rt/0CZ3vkFeBc40Xn5HeCYpKme95yirB96krIi2SHbp4lYJKleGRHRuJzRR0Q0LkEfEdG4BH1EROMS9BERjUvQR0Q0LkEfEdG4BH1EROP+Azb0Pnpx1lNbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,11),accuracies)\n",
    "plt.xlabel('Fold Iteration')\n",
    "plt.title(\"K-Fold Cross Validation Accuracy\")\n",
    "#plt.savefig(\"ann_k_fold.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6076389 , 0.62152779, 0.625     , 0.59930313, 0.66898954,\n",
       "       0.62717772, 0.64459932, 0.60278744, 0.65156794, 0.67944252])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch validation model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to introduce model training in keras with Gridsearch\n",
    "def build_classifier(optimizer):\n",
    "    #ANN Model\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu', input_dim = 159))\n",
    "    classifier.add(Dense(output_dim = 50,init = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(output_dim = 1,init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    #compiling the model\n",
    "    classifier.compile(optimizer = optimizer,\n",
    "                      loss = 'binary_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_sk = KerasClassifier(build_fn = build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for GridSearch\n",
    "params = {'batch_size':[25,32],\n",
    "          'epochs': [100,500],\n",
    "          'optimizer': ['adam','rmsprop']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch for ANN\n",
    "grid_search = GridSearchCV(estimator=classifier_sk,\n",
    "                          param_grid = params,\n",
    "                          scoring='accuracy',\n",
    "                          cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2585/2585 [==============================] - 0s 162us/step - loss: 0.6248 - accuracy: 0.6638\n",
      "Epoch 2/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.5772 - accuracy: 0.6762\n",
      "Epoch 3/100\n",
      "2585/2585 [==============================] - 0s 110us/step - loss: 0.5574 - accuracy: 0.7025\n",
      "Epoch 4/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 0.5346 - accuracy: 0.7288\n",
      "Epoch 5/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.5198 - accuracy: 0.7505\n",
      "Epoch 6/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 0.5000 - accuracy: 0.7551\n",
      "Epoch 7/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.4801 - accuracy: 0.7752\n",
      "Epoch 8/100\n",
      "2585/2585 [==============================] - 0s 111us/step - loss: 0.4504 - accuracy: 0.7930\n",
      "Epoch 9/100\n",
      "2585/2585 [==============================] - 0s 115us/step - loss: 0.4313 - accuracy: 0.8031\n",
      "Epoch 10/100\n",
      "2585/2585 [==============================] - 0s 112us/step - loss: 0.4050 - accuracy: 0.8213\n",
      "Epoch 11/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 0.3765 - accuracy: 0.8360\n",
      "Epoch 12/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.3481 - accuracy: 0.8507\n",
      "Epoch 13/100\n",
      "2585/2585 [==============================] - 0s 110us/step - loss: 0.3196 - accuracy: 0.8700\n",
      "Epoch 14/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 0.2997 - accuracy: 0.8689\n",
      "Epoch 15/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 0.2725 - accuracy: 0.8890\n",
      "Epoch 16/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 0.2414 - accuracy: 0.9037\n",
      "Epoch 17/100\n",
      "2585/2585 [==============================] - 0s 109us/step - loss: 0.2200 - accuracy: 0.9219\n",
      "Epoch 18/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 0.1959 - accuracy: 0.9242\n",
      "Epoch 19/100\n",
      "2585/2585 [==============================] - 0s 111us/step - loss: 0.1859 - accuracy: 0.9300\n",
      "Epoch 20/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 0.1510 - accuracy: 0.9455\n",
      "Epoch 21/100\n",
      "2585/2585 [==============================] - 0s 111us/step - loss: 0.1295 - accuracy: 0.9536\n",
      "Epoch 22/100\n",
      "2585/2585 [==============================] - 0s 117us/step - loss: 0.1159 - accuracy: 0.9613\n",
      "Epoch 23/100\n",
      "2585/2585 [==============================] - 0s 110us/step - loss: 0.1303 - accuracy: 0.9544\n",
      "Epoch 24/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.1302 - accuracy: 0.9547\n",
      "Epoch 25/100\n",
      "2585/2585 [==============================] - 0s 111us/step - loss: 0.0925 - accuracy: 0.9749\n",
      "Epoch 26/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 0.0712 - accuracy: 0.9787\n",
      "Epoch 27/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 0.0676 - accuracy: 0.9853\n",
      "Epoch 28/100\n",
      "2585/2585 [==============================] - 0s 127us/step - loss: 0.0464 - accuracy: 0.9919\n",
      "Epoch 29/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 0.0347 - accuracy: 0.9946\n",
      "Epoch 30/100\n",
      "2585/2585 [==============================] - 0s 111us/step - loss: 0.0230 - accuracy: 0.9977\n",
      "Epoch 31/100\n",
      "2585/2585 [==============================] - 0s 110us/step - loss: 0.0194 - accuracy: 0.9977\n",
      "Epoch 32/100\n",
      "2585/2585 [==============================] - 0s 115us/step - loss: 0.0150 - accuracy: 0.9988\n",
      "Epoch 33/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "2585/2585 [==============================] - 0s 110us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "2585/2585 [==============================] - 0s 101us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "2585/2585 [==============================] - 0s 115us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "2585/2585 [==============================] - 0s 110us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "2585/2585 [==============================] - 0s 109us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 9.6052e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 8.7503e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 8.0877e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 7.4596e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 6.8095e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 6.2563e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 5.8541e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 5.3255e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 4.9392e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 4.5753e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 4.2688e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 3.9304e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 3.6650e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 3.3991e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "2585/2585 [==============================] - 0s 109us/step - loss: 3.1693e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 2.9725e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 2.7445e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 2.5532e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 2.3694e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 2.2440e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 2.0479e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 1.9202e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "2585/2585 [==============================] - 0s 103us/step - loss: 1.7843e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2585/2585 [==============================] - 0s 106us/step - loss: 1.6789e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 1.5662e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 1.4691e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 1.3504e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 1.2728e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 1.1877e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "2585/2585 [==============================] - 0s 109us/step - loss: 1.1032e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 1.0352e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 9.7788e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 9.1424e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "2585/2585 [==============================] - 0s 110us/step - loss: 8.5138e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 7.9700e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 7.4801e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 6.9758e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "2585/2585 [==============================] - 0s 108us/step - loss: 6.5188e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 6.1799e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 5.7234e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 5.4222e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "2585/2585 [==============================] - 0s 104us/step - loss: 5.1020e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 4.8124e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "2585/2585 [==============================] - 0s 102us/step - loss: 4.4530e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "2585/2585 [==============================] - 0s 107us/step - loss: 4.1986e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "2585/2585 [==============================] - 0s 105us/step - loss: 3.9149e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "2585/2585 [==============================] - 0s 106us/step - loss: 3.6674e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2a6a95ca35ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#training for gridsearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# grid =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# best_params = grid.best_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# best_accuracy = grid.best_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \"\"\"\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 97\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown is not supported"
     ]
    }
   ],
   "source": [
    "#training for gridsearch\n",
    "# grid = \n",
    "grid_search.fit(X_train,y_train)\n",
    "# best_params = grid.best_params_\n",
    "# best_accuracy = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
